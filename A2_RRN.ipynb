{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "A2_RRN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iB46BeW4os-O",
        "qFkeLiakYYj8",
        "qZoXwM8jVcSK"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkjsQG1JQkF"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UbIwRwjiIk7",
        "outputId": "56a25c67-890f-4d8f-f783-68e730bb7e7e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFkeLiakYYj8"
      },
      "source": [
        "# repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K25IZJgjpegr"
      },
      "source": [
        "def compute_cp(pred, true): # pred and true are of shape = batch,81\n",
        "    # number of exactly correct predictions\n",
        "    return torch.sum(torch.sum(pred==true,dim=1)==81)\n",
        "\n",
        "def compute_micro_score(pred, true):\n",
        "    # this finds percentage of correct predicited digits and then averaged over batch\n",
        "    temp = 100.*torch.sum(pred==true,dim=1)/81.\n",
        "    return torch.sum(temp)/temp.shape[0]\n",
        "\n",
        "def get_edges():\n",
        "    def cross(a):\n",
        "        return [(i, j) for i in a.flatten() for j in a.flatten() if not i == j]\n",
        "\n",
        "    idx = np.arange(81).reshape(9, 9)\n",
        "    rows, columns, squares = [], [], []\n",
        "    for i in range(9):\n",
        "        rows += cross(idx[i, :])\n",
        "        columns += cross(idx[:, i])\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            squares += cross(idx[i * 3:(i + 1) * 3, j * 3:(j + 1) * 3])\n",
        "    \n",
        "    edges_base = list(set(rows + columns + squares))\n",
        "    batched_edges = [(i + (b * 81), j + (b * 81)) for b in range(BATCH_SIZE) for i, j in edges_base]\n",
        "    return torch.Tensor(batched_edges).long()\n",
        "\n",
        "def get_start_embeds(embed, X):\n",
        "    X = embed(X.long(), EMB_SIZE).float()\n",
        "    return X\n",
        "\n",
        "\n",
        "def message_passing(nodes, edges, message_fn):\n",
        "    n_nodes = nodes.shape[0]\n",
        "    n_edges = edges.shape[0]\n",
        "    n_embed = nodes.shape[1]\n",
        "\n",
        "    message_inputs = nodes[edges]\n",
        "    message_inputs = message_inputs.view(n_edges, 2*n_embed)\n",
        "    messages = message_fn(message_inputs)\n",
        "\n",
        "    updates = torch.zeros(n_nodes, n_embed).to(device)\n",
        "    idx_j = edges[:, 1].to(device)\n",
        "    updates = updates.index_add(0, idx_j, messages)\n",
        "    return updates\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_size, HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc_out = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "class Pred(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Pred, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "def check_val():\n",
        "    with torch.no_grad():\n",
        "        almost_correct = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_id, (X_batched, Y_batched) in enumerate(testloader):\n",
        "            if X_batched.shape[0] != BATCH_SIZE:\n",
        "                continue\n",
        "            X = X_batched.flatten()\n",
        "\n",
        "            X = get_start_embeds(embed, X)\n",
        "            X = X.to(device)\n",
        "            Y_batched = Y_batched.to(device)\n",
        "            X = mlp1(X)\n",
        "            H = X.detach().clone().to(device)\n",
        "\n",
        "            CellState = torch.zeros(X.shape).to(device)\n",
        "            HiddenState = torch.zeros(X.shape).to(device)\n",
        "            for i in range(32):\n",
        "                H = message_passing(H, edges, mlp2) # message_fn\n",
        "                H = mlp3(torch.cat([H, X], dim=1))\n",
        "                HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "                H = CellState\n",
        "                pred = r(H)\n",
        "\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "            pred = pred.view(-1, 81).cpu()\n",
        "            Y_batched = Y_batched.view(32, -1).cpu()\n",
        "            amam = torch.sum(pred == Y_batched, dim=1)\n",
        "\n",
        "            correct += torch.sum(torch.sum(pred == Y_batched, dim=1) == 81)\n",
        "            almost_correct += torch.sum(torch.sum(pred == Y_batched, dim=1) >= 60)\n",
        "            total += Y_batched.shape[0]\n",
        "\n",
        "            if batch_id == 0:\n",
        "                print(\"predicted:\",pred[0])\n",
        "                print(\"true:\",Y_batched[0])\n",
        "        \n",
        "\n",
        "        print(\"Correctly solved: {}, out of: {}\".format(correct, total))\n",
        "        print(\"Almost correctly solved: {}, out of: {}\".format(almost_correct, total))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew505WhpJQkY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "a055785a-c90c-4d64-8916-64fc9906fe42"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMB_SIZE = 16\n",
        "HIDDEN_SIZE = 96\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:1500]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:1500]\n",
        "batch_size=32\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[:1024]),torch.tensor(data_Y[:1024]))\n",
        "trainloader=DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[1024:]),torch.tensor(data_Y[1024:]))\n",
        "testloader=DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "mlp1 = MLP(EMB_SIZE).to(device)\n",
        "mlp2 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "mlp3 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "r = Pred(HIDDEN_SIZE).to(device)\n",
        "lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE).to(device)\n",
        "embed = torch.nn.functional.one_hot\n",
        "\n",
        "optimizer_mlp1 = torch.optim.Adam(mlp1.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp2 = torch.optim.Adam(mlp2.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp3 = torch.optim.Adam(mlp3.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_r = torch.optim.Adam(r.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "optimizers = [optimizer_mlp1, optimizer_mlp2, optimizer_mlp3, optimizer_r, optimizer_lstm]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "edges = get_edges()\n",
        "\n",
        "for epoch in range(100):\n",
        "    lss = 0\n",
        "    print(\"Started epoch: \", epoch)\n",
        "    total, correct, micro_score = 0, 0, 0\n",
        "    for batch_id, (X, Y) in enumerate(trainloader):\n",
        "        if X.shape[0] != BATCH_SIZE:\n",
        "            continue\n",
        "\n",
        "        X = X.flatten()\n",
        "        Y = Y.flatten()\n",
        "        X = get_start_embeds(embed, X)\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "        X = mlp1(X)\n",
        "        H = X.detach().clone().to(device)\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        loss = 0\n",
        "        CellState = torch.zeros(X.shape).to(device)\n",
        "        HiddenState = torch.zeros(X.shape).to(device)\n",
        "        for i in range(32):\n",
        "            H = message_passing(H, edges, mlp2) # message_fn\n",
        "            H = mlp3(torch.cat([H, X], dim=1))\n",
        "            HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "            H = HiddenState\n",
        "            pred = r(H)\n",
        "            loss += criterion(pred, Y.long())\n",
        "        \n",
        "        loss /= BATCH_SIZE\n",
        "        loss.backward()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "    # check_val()\n",
        "         \n",
        "        lss += loss.item()\n",
        "\n",
        "        pred = pred.argmax(dim=1).view(-1,81)\n",
        "        Y = Y.view(-1,81)\n",
        "\n",
        "        correct_predictions = compute_cp(pred.cpu(),Y.cpu()) # number of exactly correct predictions\n",
        "        correct += correct_predictions\n",
        "        total += Y.shape[0]\n",
        "\n",
        "        micro_correct_digits = compute_micro_score(pred.cpu(),Y.cpu()) # this finds percentage of correct predicited digits and then averaged over batch\n",
        "        micro_score += micro_correct_digits\n",
        "        \n",
        "    micro_score /= batch_id\n",
        "    lss /= batch_id\n",
        "\n",
        "    print(\"epoch:\",epoch,\"|loss:\",lss,\"| Completely correct predictions:\",100.*correct/total,\"| Percentage of Correctly predicted digits:\",micro_score)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started epoch:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 |loss: 2.3368322695455244 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "Started epoch:  1\n",
            "epoch: 1 |loss: 2.275004425356465 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.6288)\n",
            "Started epoch:  2\n",
            "epoch: 2 |loss: 2.269856306814378 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.7707)\n",
            "Started epoch:  3\n",
            "epoch: 3 |loss: 2.2691740451320523 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.6151)\n",
            "Started epoch:  4\n",
            "epoch: 4 |loss: 2.268906062649142 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.9437)\n",
            "Started epoch:  5\n",
            "epoch: 5 |loss: 2.268739915663196 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.6711)\n",
            "Started epoch:  6\n",
            "epoch: 6 |loss: 2.26833854183074 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(13.6798)\n",
            "Started epoch:  7\n",
            "epoch: 7 |loss: 2.268756781854937 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(13.7109)\n",
            "Started epoch:  8\n",
            "epoch: 8 |loss: 2.256213311226137 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(14.8920)\n",
            "Started epoch:  9\n",
            "epoch: 9 |loss: 2.1304402582107054 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(19.5042)\n",
            "Started epoch:  10\n",
            "epoch: 10 |loss: 1.9415673594320975 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(26.8718)\n",
            "Started epoch:  11\n",
            "epoch: 11 |loss: 1.7932744410730177 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(32.2282)\n",
            "Started epoch:  12\n",
            "epoch: 12 |loss: 1.7166463136672974 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(41.8695)\n",
            "Started epoch:  13\n",
            "epoch: 13 |loss: 1.6617931627458142 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(49.6229)\n",
            "Started epoch:  14\n",
            "epoch: 14 |loss: 1.6069593275746992 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(51.2557)\n",
            "Started epoch:  15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-38a7dec54f6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBRkuyytG0ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6T_gX2y-1d6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZoXwM8jVcSK"
      },
      "source": [
        "# Copying from repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F19y0XWhUfrC",
        "outputId": "b240b488-9a59-4bd5-9368-7b30908847e4"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MLP_for_RRN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_for_RRN, self).__init__()\n",
        "        self.fc1=nn.Linear(input_dim, output_dim)\n",
        "        self.fc2=nn.Linear(output_dim, output_dim)\n",
        "        self.fc3=nn.Linear(output_dim, output_dim)\n",
        "        # self.fc4=nn.Linear(output_dim, output_dim)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.fc1(inp))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        # out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "def compute_cp(pred, true): # pred and true are of shape = batch,81\n",
        "    # number of exactly correct predictions\n",
        "    return torch.sum(torch.sum(pred==true,dim=1)==81)\n",
        "\n",
        "def compute_micro_score(pred, true):\n",
        "    # this finds percentage of correct predicited digits and then averaged over batch\n",
        "    temp = 100.*torch.sum(pred==true,dim=1)/81.\n",
        "    return torch.sum(temp)/temp.shape[0]\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "embed_dim=16\n",
        "sudoku_cells=9\n",
        "hidden_dim=96\n",
        "num_steps=32\n",
        "batch_size=32\n",
        "\n",
        "\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:1500]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:1500]\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[:1024]),torch.tensor(data_Y[:1024]))\n",
        "trainloader=DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[1024:]),torch.tensor(data_Y[1024:]))\n",
        "testloader=DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "embeds_to_x = MLP_for_RRN(3*embed_dim, hidden_dim).to(device)\n",
        "message_mlp = MLP_for_RRN(2*hidden_dim, hidden_dim).to(device)\n",
        "mlp_for_lstm_inp = MLP_for_RRN(2*hidden_dim, hidden_dim).to(device)\n",
        "r_to_o_mlp = nn.Linear(hidden_dim, sudoku_cells+1).to(device) # only one linear layer as given in architecture details\n",
        "mlps = [embeds_to_x, message_mlp, mlp_for_lstm_inp, r_to_o_mlp]\n",
        "LSTM = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim).to(device)# since x and m will be concatentated and fed into lstm; x and m are of shape : batch_size*9*9, hidden_dim\n",
        "\n",
        "\n",
        "embed = torch.nn.functional.one_hot ## ALERT\n",
        "\n",
        "# embed_1 = nn.Linear(sudoku_cells+1,embed_dim)\n",
        "\n",
        "# embed_1 = nn.Embedding.from_pretrained(torch.rand(sudoku_cells+1, embed_dim).to(device)).to(device)\n",
        "\n",
        "\n",
        "optimizers = []\n",
        "for mlp in mlps:\n",
        "    optimizers.append(optim.Adam(mlp.parameters(), lr=2e-4, weight_decay=1e-4))\n",
        "optimizers.append(optim.Adam(LSTM.parameters(), lr=2e-4, weight_decay=1e-4))\n",
        "\n",
        "# optimizers.append(optim.Adam(embed_1.parameters(), lr=2e-4, weight_decay=1e-4))\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "############################ get edges\n",
        "# find the required edges in the graph to have communication of message signals\n",
        "indices_of_cells=np.arange(0,sudoku_cells*sudoku_cells).reshape((sudoku_cells,sudoku_cells))\n",
        "edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "for i in range(9):\n",
        "    vector = indices_of_cells[i,:]\n",
        "    edges_row += [(i,j) for i in vector for j in vector if i!=j]\n",
        "    vector = indices_of_cells[:,i]\n",
        "    edges_col += [(i,j) for i in vector for j in vector if i!=j]\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        vector = indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1)\n",
        "        edges_in_3x3 += [(i,j) for i in vector for j in vector if i!=j]\n",
        "\n",
        "edges = list(set(edges_row + edges_col + edges_in_3x3))\n",
        "# edges = [ (i + (b*81), j + (b*81)) for b in range(batch_size) for i,j in edges]\n",
        "edges = torch.tensor(edges).long().to(device)\n",
        "# self.edges contains all the possible pairs of communication between the cells of sudoku\n",
        "############################\n",
        "\n",
        "\n",
        "\n",
        "############################ FOR EMBEDDING ROW, COL INFORMATION\n",
        "# create row and col labels for the cells of sudoku table\n",
        "row_col = []\n",
        "for i in range(sudoku_cells):\n",
        "    for j in range(sudoku_cells):\n",
        "        row_col.append((i,j))\n",
        "row_col = torch.tensor(row_col).long()\n",
        "############################\n",
        "\n",
        "\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "    lss = 0\n",
        "        \n",
        "    total, correct, micro_score = 0, 0, 0\n",
        "\n",
        "    for batch_id, (X,Y) in enumerate(trainloader):\n",
        "        if X.shape[0]!=batch_size:\n",
        "            continue\n",
        "\n",
        "        X = X.flatten()\n",
        "        Y = Y.flatten()\n",
        "        # if epoch == 0 and batch_id == 0:\n",
        "        #     print('printing X shape: ', X.shape)\n",
        "        \n",
        "        X = embed(X.long(), embed_dim).float()\n",
        "        row_col_batched = row_col.repeat(batch_size,1) # IMPORTANT - HERE REMOVE BATCH_SIZE VARIABLE LATER\n",
        "        embedded_row = embed(row_col_batched[:,0].long(), embed_dim).float()\n",
        "        embedded_col = embed(row_col_batched[:,1].long(), embed_dim).float()\n",
        "        \n",
        "        X = torch.cat([X,embedded_row,embedded_col],dim=1)\n",
        "        # X = F.one_hot(X.long(), sudoku_cells+1).float()\n",
        "        \n",
        "        # if epoch == 0 and batch_id == 0:\n",
        "        #     print('printing embedded X shape: ', X.shape)\n",
        "\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        # X = embed_1(X)\n",
        "\n",
        "        X = embeds_to_x(X)\n",
        "\n",
        "        H = X.detach().clone().to(device)\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "        HiddenState,CellState = torch.zeros(X.shape).to(device), torch.zeros(X.shape).to(device)\n",
        "\n",
        "        for i in range(num_steps):\n",
        "\n",
        "            n_nodes = H.shape[0]\n",
        "            n_edges = edges.shape[0]\n",
        "            n_embed = H.shape[1]\n",
        "            assert n_embed == 96\n",
        "\n",
        "            H = H.view(-1,81,96)\n",
        "\n",
        "            assert H.shape[0] == 32\n",
        "\n",
        "            message_inputs = H[:,edges]\n",
        "            message_inputs = message_inputs.view(-1, 2*96)\n",
        "\n",
        "            messages = message_mlp(message_inputs).view(H.shape[0],-1,96)\n",
        "\n",
        "            updates = torch.zeros(H.shape).to(device)\n",
        "            idx_j = edges[:, 1].to(device)\n",
        "            H = updates.index_add(1, idx_j, messages)\n",
        "\n",
        "            H = H.view(-1,96)\n",
        "\n",
        "            H = mlp_for_lstm_inp(torch.cat([H, X], dim=1))\n",
        "            HiddenState, CellState = LSTM(H, (HiddenState, CellState))\n",
        "\n",
        "            H = HiddenState ## ALERT\n",
        "\n",
        "            Y_pred = r_to_o_mlp(H)\n",
        "\n",
        "            loss += loss_fn(Y_pred, Y.long())\n",
        "\n",
        "        loss /= batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        lss += loss.item()\n",
        "\n",
        "        Y_pred = Y_pred.argmax(dim=1).view(-1,81)\n",
        "        Y = Y.view(-1,81)\n",
        "\n",
        "        correct_predictions = compute_cp(Y_pred.cpu(),Y.cpu()) # number of exactly correct predictions\n",
        "        correct += correct_predictions\n",
        "        total += Y.shape[0]\n",
        "\n",
        "        micro_correct_digits = compute_micro_score(Y_pred.cpu(),Y.cpu()) # this finds percentage of correct predicited digits and then averaged over batch\n",
        "        micro_score += micro_correct_digits\n",
        "        \n",
        "    micro_score /= batch_id\n",
        "    lss /= batch_id\n",
        "\n",
        "    print(\"epoch:\",epoch,\"|loss:\",lss,\"| Completely correct predictions:\",100.*correct/total,\"| Percentage of Correctly predicted digits:\",micro_score)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 |loss: 2.332360367621145 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4708)\n",
            "epoch: 1 |loss: 2.2722580432891846 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 2 |loss: 2.2695021860061155 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 3 |loss: 2.26906600306111 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 4 |loss: 2.2688424510340535 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 5 |loss: 2.268687140557074 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.5405)\n",
            "epoch: 6 |loss: 2.268586358716411 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.5268)\n",
            "epoch: 7 |loss: 2.26853689839763 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4807)\n",
            "epoch: 8 |loss: 2.2684697643403084 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 9 |loss: 2.268428671744562 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 10 |loss: 2.268394954742924 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.6575)\n",
            "epoch: 11 |loss: 2.2683665137137137 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 12 |loss: 2.268342141182192 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 13 |loss: 2.268321737166374 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 14 |loss: 2.268304555646835 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 15 |loss: 2.2682895352763515 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Traceback (most recent call last):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-add8ec3707e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhOFV9bJUiGn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfbLHjc2UiDX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zUOIM4EUiBE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQNpiZjmYe7x"
      },
      "source": [
        "# my implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alMmIKGyJQkn"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MLP_for_RRN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_for_RRN, self).__init__()\n",
        "        self.fc1=nn.Linear(input_dim, output_dim)\n",
        "        self.fc2=nn.Linear(output_dim, output_dim)\n",
        "        self.fc3=nn.Linear(output_dim, output_dim)\n",
        "        # self.fc4=nn.Linear(output_dim, output_dim)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.fc1(inp))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        # out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class RRN(nn.Module):\n",
        "    def __init__(self, embed_dim=16, sudoku_cells=9, hidden_dim=96, num_steps=32, device='cpu'):\n",
        "        # sudoku_cells means we will have sudoku_cells x sudoku_cells in the sudoku table\n",
        "        super(RRN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_steps = num_steps\n",
        "        self.device = device\n",
        "        \n",
        "\n",
        "        ############################ FOR MESSAGE SIGNALS\n",
        "        # find the required edges in the graph to have communication of message signals\n",
        "        indices_of_cells=np.arange(0,sudoku_cells*sudoku_cells).reshape((sudoku_cells,sudoku_cells))\n",
        "        edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "        for i in range(9):\n",
        "            vector = indices_of_cells[i,:]\n",
        "            edges_row += [(i,j) for i in vector for j in vector if i!=j]\n",
        "            vector = indices_of_cells[:,i]\n",
        "            edges_col += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                vector = indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1)\n",
        "                edges_in_3x3 += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        self.edges = torch.tensor(list(set(edges_row + edges_col + edges_in_3x3))).long().to(device)\n",
        "        # self.edges contains all the possible pairs of communication between the cells of sudoku\n",
        "        ############################\n",
        "        \n",
        "        \n",
        "\n",
        "        ############################ FOR EMBEDDING ROW, COL INFORMATION\n",
        "        # create row and col labels for the cells of sudoku table\n",
        "        row_col = []\n",
        "        for i in range(sudoku_cells):\n",
        "            for j in range(sudoku_cells):\n",
        "                row_col.append((i,j))\n",
        "        self.row_col = torch.tensor(row_col).long().to(device)\n",
        "        ############################\n",
        "        \n",
        "        \n",
        "\n",
        "        ############################ EMBEDDING LAYERS\n",
        "        # embedding the cell content {0,1,2,...,sudoku_cells}, row and column information for each cell in sudoku\n",
        "        self.embed_dim = embed_dim\n",
        "        # embed_1_init = torch.rand(sudoku_cells+1, self.embed_dim).to(device) #sudoku_cells+1 because possible digits in input : 0,1,2,3,...,sudoku_cells\n",
        "        # self.embed_1 = nn.Linear(sudoku_cells+1, self.embed_dim)#nn.Embedding.from_pretrained(embed_1_init, freeze=False) \n",
        "        # embed_2_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        # self.embed_2 = nn.Linear(sudoku_cells, self.embed_dim)#nn.Embedding.from_pretrained(embed_2_init, freeze=False)\n",
        "        # embed_3_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        # self.embed_3 = nn.Linear(sudoku_cells, self.embed_dim)#nn.Embedding.from_pretrained(embed_3_init, freeze=False)\n",
        "        ############################\n",
        "\n",
        "\n",
        "        ############################ MLPs\n",
        "        self.embeds_to_x = MLP_for_RRN(3*embed_dim, hidden_dim)\n",
        "        self.message_mlp = MLP_for_RRN(2*hidden_dim, hidden_dim)\n",
        "        self.mlp_for_lstm_inp = MLP_for_RRN(2*hidden_dim, hidden_dim)\n",
        "        self.r_to_o_mlp = nn.Linear(hidden_dim, sudoku_cells+1) # only one linear layer as given in architecture details\n",
        "        ############################\n",
        "\n",
        "\n",
        "        # LSTM for looping over time i.e. num_steps\n",
        "        self.LSTM = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim) # since x and m will be concatentated and fed into lstm; x and m are of shape : batch_size*9*9, hidden_dim\n",
        "        \n",
        "        \n",
        "    def forward(self, inp): # inp.shape=batch_size,9*9\n",
        "        bs = inp.shape[0]\n",
        "        inp = inp.view(-1)\n",
        "\n",
        "\n",
        "        # embed the cell content\n",
        "        inp = F.one_hot(inp, self.embed_dim).float()\n",
        "        embedded_inp = inp # batch_size*9*9, embed_dim\n",
        "        \n",
        "        # now also get row and column info of each cell embedded\n",
        "        row_col = self.row_col.repeat(batch_size, 1)\n",
        "        inp_row = F.one_hot(row_col[:,0], self.embed_dim).float()\n",
        "        embedded_row = inp_row\n",
        "        inp_col = F.one_hot(row_col[:,1], self.embed_dim).float()\n",
        "        embedded_col = inp_col\n",
        "        \n",
        "        embedded_all = torch.cat([embedded_inp,embedded_row,embedded_col], dim=1)\n",
        "        x = self.embeds_to_x(embedded_all) # batch_size*9*9, hidden_dim\n",
        "        \n",
        "        assert x.shape[1] == self.hidden_dim\n",
        "        \n",
        "\n",
        "        # x will be concatenated with m and then fed into LSTM\n",
        "        # find message signals : over time i.e. num_steps\n",
        "        # m_{i,j}^{t} = MLP(h_{i}^{t-1}, h_{j}^{t-1} \n",
        "        # since m^t requires h^{t-1}, maintain a list of h and c\n",
        "        # cell state is also required since we will use LSTM cell and loop over LSTM cell num_steps times\n",
        "        \n",
        "        h_for_msgs = x.detach().clone().to(self.device)\n",
        "        o_t = []\n",
        "\n",
        "        for t in range(self.num_steps):\n",
        "\n",
        "            h_for_msgs = h_for_msgs.view(-1, 81, self.hidden_dim)\n",
        "            inp_for_msgs = h_for_msgs[:,self.edges].view(-1, 2*self.hidden_dim)\n",
        "            msgs = self.message_mlp(inp_for_msgs).view(bs, -1, self.hidden_dim)\n",
        "            \n",
        "\n",
        "            # now sum up the message signals appropriately\n",
        "            final_msgs = torch.zeros(h_for_msgs.shape).to(device)\n",
        "            indices = self.edges[:,1].to(device)\n",
        "            final_msgs = final_msgs.index_add(1, indices, msgs) # shape : batch_size, 81, self.hidden_dim\n",
        "            final_msgs = final_msgs.view(-1, self.hidden_dim)\n",
        "            \n",
        "            # h_for_msgs = h_for_msgs.view(-1, self.hidden_dim) # required for input to lstm cell\n",
        "            \n",
        "            inp_to_lstm = self.mlp_for_lstm_inp(torch.cat([final_msgs,x],dim=1))\n",
        "            h, c = self.LSTM(inp_to_lstm, (h,c)) if t!=0 else self.LSTM(inp_to_lstm, (h_for_msgs.view(-1, 96), torch.zeros(x.shape).to(device)))\n",
        "            \n",
        "            h_for_msgs = h\n",
        "\n",
        "            o = self.r_to_o_mlp(h)\n",
        "            o_t.append(o)\n",
        "        \n",
        "        out = torch.stack(o_t) # shape : num_steps, batch_size*9*9, sudoku_cells+1\n",
        "        return out # out.shape = num_steps, batch_size*9*9, 10 : last dim is without-softmax over sudoku_cells(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKwjxQuiovrg",
        "outputId": "e8064706-1e13-4e4a-c0d4-6989de7391b1"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_cp(pred, true): # pred and true are of shape = batch,81\n",
        "    # number of exactly correct predictions\n",
        "    return torch.sum(torch.sum(pred==true,dim=1)==81)\n",
        "\n",
        "def compute_micro_score(pred, true):\n",
        "    # this finds percentage of correct predicited digits and then averaged over batch\n",
        "    temp = 100.*torch.sum(pred==true,dim=1)/81.\n",
        "    return torch.sum(temp)/temp.shape[0]\n",
        "\n",
        "batch_size=64\n",
        "embed_dim=16\n",
        "sudoku_cells=9\n",
        "hidden_dim=96\n",
        "num_steps=32\n",
        "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:1024]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:1024]\n",
        "dataset=TensorDataset(torch.tensor(data_X),torch.tensor(data_Y))\n",
        "data_loader=DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "model = RRN(embed_dim=embed_dim, sudoku_cells=sudoku_cells, hidden_dim=hidden_dim, num_steps=num_steps, device=device)\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "loss_fn=nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RRN(\n",
            "  (embeds_to_x): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=48, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (message_mlp): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (mlp_for_lstm_inp): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (r_to_o_mlp): Linear(in_features=96, out_features=10, bias=True)\n",
            "  (LSTM): LSTMCell(96, 96)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "jc0_fgSAqL9q",
        "outputId": "f1002b38-0a56-49a9-dfe1-2757e1ce7741"
      },
      "source": [
        "num_epochs=100\n",
        "train_loss=[]\n",
        "for epoch in range(num_epochs):\n",
        "    lss=0\n",
        "\n",
        "    total, correct, micro_score = 0, 0, 0\n",
        "\n",
        "    for batch_id, (X,Y) in enumerate(data_loader):\n",
        "        if X.shape[0] != batch_size:\n",
        "            continue\n",
        "\n",
        "        X, Y = X.to(device).long(), Y.to(device)\n",
        "        Y = Y.view(-1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        Y_ = model(X)\n",
        "        \n",
        "        l=0\n",
        "        for i in range(num_steps):\n",
        "            ls=loss_fn(Y_[i],Y.long())\n",
        "            l+=ls\n",
        "\n",
        "        Y_pred = Y_[-1].argmax(dim=1)\n",
        "\n",
        "        l /= batch_size\n",
        "        l.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1) # clip gradient to 5\n",
        "        optimizer.step()\n",
        "        \n",
        "        Y_pred = Y_pred.view(-1,81)\n",
        "        Y = Y.view(-1,81)\n",
        "        \n",
        "        assert X.shape[0]==Y.shape[0]\n",
        "\n",
        "        lss += l.item()\n",
        "        correct_predictions = compute_cp(Y_pred.cpu(),Y.cpu()) # number of exactly correct predictions\n",
        "        correct += correct_predictions\n",
        "        total += Y.shape[0]\n",
        "\n",
        "        micro_correct_digits = compute_micro_score(Y_pred.cpu(),Y.cpu()) # this finds percentage of correct predicited digits and then averaged over batch\n",
        "        micro_score += micro_correct_digits\n",
        "        \n",
        "    lss /= batch_id\n",
        "    micro_score /= batch_id\n",
        "    print(\"epoch:\",epoch,\"|\tloss:\",lss,\"| Completely correct predictions:\",100.*correct/total,\"| Percentage of Correctly predicted digits:\",micro_score)\n",
        "    \n",
        "    # scheduler.step(lss)\n",
        "\n",
        "torch.save(model.state_dict(),'RRN.pth')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-542806722a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mY_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-f9c238399399>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mh_for_msgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_for_msgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m81\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0minp_for_msgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_for_msgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mmsgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_for_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-f9c238399399>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# out = self.fc4(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 14.76 GiB total capacity; 13.60 GiB already allocated; 21.75 MiB free; 13.71 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE-1T04KUfQc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuwuVmaGUfNJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jchJJCD2UfKJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEgcNzvKL9mg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IA2qkrkHF6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgykbYcPCFbK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRpB0MpNUgA2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIPk-qwgUf-F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwW6ih0VUf8a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLDGKGeIUf5r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypz2hcl8Uf2Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}