{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "A2_RRN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qFkeLiakYYj8"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkjsQG1JQkF"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UbIwRwjiIk7",
        "outputId": "7636bd5d-4a08-44ff-eb58-11ed0529b3bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFkeLiakYYj8"
      },
      "source": [
        "# repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K25IZJgjpegr"
      },
      "source": [
        "def compute_cp(pred, true): # pred and true are of shape = batch,81\n",
        "    # number of exactly correct predictions\n",
        "    return torch.sum(torch.sum(pred==true,dim=1)==81)\n",
        "\n",
        "def compute_micro_score(pred, true):\n",
        "    # this finds percentage of correct predicited digits and then averaged over batch\n",
        "    temp = 100.*torch.sum(pred==true,dim=1)/81.\n",
        "    return torch.sum(temp)/temp.shape[0]\n",
        "\n",
        "def get_edges():\n",
        "    def cross(a):\n",
        "        return [(i, j) for i in a.flatten() for j in a.flatten() if not i == j]\n",
        "\n",
        "    idx = np.arange(81).reshape(9, 9)\n",
        "    rows, columns, squares = [], [], []\n",
        "    for i in range(9):\n",
        "        rows += cross(idx[i, :])\n",
        "        columns += cross(idx[:, i])\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            squares += cross(idx[i * 3:(i + 1) * 3, j * 3:(j + 1) * 3])\n",
        "    \n",
        "    edges_base = list(set(rows + columns + squares))\n",
        "    batched_edges = [(i + (b * 81), j + (b * 81)) for b in range(BATCH_SIZE) for i, j in edges_base]\n",
        "    return torch.Tensor(batched_edges).long()\n",
        "\n",
        "def get_start_embeds(embed, X):\n",
        "    X = embed(X.long(), EMB_SIZE).float()\n",
        "    return X\n",
        "\n",
        "\n",
        "def message_passing(nodes, edges, message_fn):\n",
        "    n_nodes = nodes.shape[0]\n",
        "    n_edges = edges.shape[0]\n",
        "    n_embed = nodes.shape[1]\n",
        "\n",
        "    message_inputs = nodes[edges]\n",
        "    message_inputs = message_inputs.view(n_edges, 2*n_embed)\n",
        "    messages = message_fn(message_inputs)\n",
        "\n",
        "    updates = torch.zeros(n_nodes, n_embed).to(device)\n",
        "    idx_j = edges[:, 1].to(device)\n",
        "    updates = updates.index_add(0, idx_j, messages)\n",
        "    return updates\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_size, HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc_out = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "class Pred(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Pred, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "def check_val():\n",
        "    with torch.no_grad():\n",
        "        almost_correct = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for batch_id, (X_batched, Y_batched) in enumerate(testloader):\n",
        "            if X_batched.shape[0] != BATCH_SIZE:\n",
        "                continue\n",
        "            X = X_batched.flatten()\n",
        "\n",
        "            X = get_start_embeds(embed, X)\n",
        "            X = X.to(device)\n",
        "            Y_batched = Y_batched.to(device)\n",
        "            X = mlp1(X)\n",
        "            H = X.detach().clone().to(device)\n",
        "\n",
        "            CellState = torch.zeros(X.shape).to(device)\n",
        "            HiddenState = torch.zeros(X.shape).to(device)\n",
        "            for i in range(32):\n",
        "                H = message_passing(H, edges, mlp2) # message_fn\n",
        "                H = mlp3(torch.cat([H, X], dim=1))\n",
        "                HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "                H = CellState\n",
        "                pred = r(H)\n",
        "\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "            pred = pred.view(-1, 81).cpu()\n",
        "            Y_batched = Y_batched.view(32, -1).cpu()\n",
        "            amam = torch.sum(pred == Y_batched, dim=1)\n",
        "\n",
        "            correct += torch.sum(torch.sum(pred == Y_batched, dim=1) == 81)\n",
        "            almost_correct += torch.sum(torch.sum(pred == Y_batched, dim=1) >= 60)\n",
        "            total += Y_batched.shape[0]\n",
        "\n",
        "            if batch_id == 0:\n",
        "                print(\"predicted:\",pred[0])\n",
        "                print(\"true:\",Y_batched[0])\n",
        "        \n",
        "\n",
        "        print(\"Correctly solved: {}, out of: {}\".format(correct, total))\n",
        "        print(\"Almost correctly solved: {}, out of: {}\".format(almost_correct, total))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew505WhpJQkY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8a154d4-e9d2-4077-ab85-e8c2cf0cba79"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMB_SIZE = 16\n",
        "HIDDEN_SIZE = 96\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:1500]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:1500]\n",
        "batch_size=32\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[:1024]),torch.tensor(data_Y[:1024]))\n",
        "trainloader=DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[1024:]),torch.tensor(data_Y[1024:]))\n",
        "testloader=DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "mlp1 = MLP(EMB_SIZE).to(device)\n",
        "mlp2 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "mlp3 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "r = Pred(HIDDEN_SIZE).to(device)\n",
        "lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE).to(device)\n",
        "embed = torch.nn.functional.one_hot\n",
        "\n",
        "optimizer_mlp1 = torch.optim.Adam(mlp1.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp2 = torch.optim.Adam(mlp2.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp3 = torch.optim.Adam(mlp3.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_r = torch.optim.Adam(r.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "optimizers = [optimizer_mlp1, optimizer_mlp2, optimizer_mlp3, optimizer_r, optimizer_lstm]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "edges = get_edges()\n",
        "\n",
        "for epoch in range(100):\n",
        "    lss = 0\n",
        "    print(\"Started epoch: \", epoch)\n",
        "    total, correct, micro_score = 0, 0, 0\n",
        "    for batch_id, (X, Y) in enumerate(trainloader):\n",
        "        if X.shape[0] != BATCH_SIZE:\n",
        "            continue\n",
        "\n",
        "        X = X.flatten()\n",
        "        Y = Y.flatten()\n",
        "        X = get_start_embeds(embed, X)\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "        X = mlp1(X)\n",
        "        H = X.detach().clone().to(device) #clone()\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        loss = 0\n",
        "        CellState = torch.zeros(X.shape).to(device)\n",
        "        HiddenState = torch.zeros(X.shape).to(device)\n",
        "        for i in range(32):\n",
        "            H = message_passing(H, edges, mlp2) # message_fn\n",
        "            H = mlp3(torch.cat([H, X], dim=1))\n",
        "            HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "            H = HiddenState\n",
        "            pred = r(H)\n",
        "            loss += criterion(pred, Y.long())\n",
        "        \n",
        "        loss /= BATCH_SIZE\n",
        "        loss.backward()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "    # check_val()\n",
        "         \n",
        "        lss += loss.item()\n",
        "\n",
        "        pred = pred.argmax(dim=1).view(-1,81)\n",
        "        Y = Y.view(-1,81)\n",
        "\n",
        "        correct_predictions = compute_cp(pred.cpu(),Y.cpu()) # number of exactly correct predictions\n",
        "        correct += correct_predictions\n",
        "        total += Y.shape[0]\n",
        "\n",
        "        micro_correct_digits = compute_micro_score(pred.cpu(),Y.cpu()) # this finds percentage of correct predicited digits and then averaged over batch\n",
        "        micro_score += micro_correct_digits\n",
        "        \n",
        "    micro_score /= batch_id\n",
        "    lss /= batch_id\n",
        "\n",
        "    print(\"epoch:\",epoch,\"|loss:\",lss,\"| Completely correct predictions:\",100.*correct/total,\"| Percentage of Correctly predicted digits:\",micro_score)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Started epoch:  0\n",
            "epoch: 0 |loss: 2.332685593635805 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "Started epoch:  1\n",
            "epoch: 1 |loss: 2.272683505089052 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4546)\n",
            "Started epoch:  2\n",
            "epoch: 2 |loss: 2.269278618597215 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.7558)\n",
            "Started epoch:  3\n",
            "epoch: 3 |loss: 2.2653423970745457 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(13.5317)\n",
            "Started epoch:  4\n",
            "epoch: 4 |loss: 2.218386427048714 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(16.0656)\n",
            "Started epoch:  5\n",
            "epoch: 5 |loss: 2.117998161623555 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(18.2348)\n",
            "Started epoch:  6\n",
            "epoch: 6 |loss: 1.9629744637397029 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(20.8383)\n",
            "Started epoch:  7\n",
            "epoch: 7 |loss: 1.8872955806793705 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(26.2931)\n",
            "Started epoch:  8\n",
            "epoch: 8 |loss: 1.8380246200869161 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(32.4111)\n",
            "Started epoch:  9\n",
            "epoch: 9 |loss: 1.790312901619942 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(37.0209)\n",
            "Started epoch:  10\n",
            "epoch: 10 |loss: 1.7481498718261719 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(38.1496)\n",
            "Started epoch:  11\n",
            "epoch: 11 |loss: 1.689526830950091 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(40.4197)\n",
            "Started epoch:  12\n",
            "epoch: 12 |loss: 1.6423784571309243 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(42.5329)\n",
            "Started epoch:  13\n",
            "epoch: 13 |loss: 1.6020455321957987 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(46.7929)\n",
            "Started epoch:  14\n",
            "epoch: 14 |loss: 1.5760021440444454 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(47.4587)\n",
            "Started epoch:  15\n",
            "epoch: 15 |loss: 1.5517473874553558 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(47.8731)\n",
            "Started epoch:  16\n",
            "epoch: 16 |loss: 1.5429482306203535 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(46.9795)\n",
            "Started epoch:  17\n",
            "epoch: 17 |loss: 1.5117220147963493 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(48.0785)\n",
            "Started epoch:  18\n",
            "epoch: 18 |loss: 1.4905397507452196 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(48.6460)\n",
            "Started epoch:  19\n",
            "epoch: 19 |loss: 1.4720014564452633 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(50.5563)\n",
            "Started epoch:  20\n",
            "epoch: 20 |loss: 1.4363758871632237 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(53.8344)\n",
            "Started epoch:  21\n",
            "epoch: 21 |loss: 1.4157326067647626 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(54.3222)\n",
            "Started epoch:  22\n",
            "epoch: 22 |loss: 1.397068073672633 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(54.9582)\n",
            "Started epoch:  23\n",
            "epoch: 23 |loss: 1.3660391415319135 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(56.1231)\n",
            "Started epoch:  24\n",
            "epoch: 24 |loss: 1.3962809308882682 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(54.5425)\n",
            "Started epoch:  25\n",
            "epoch: 25 |loss: 1.3569229187503937 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(55.5444)\n",
            "Started epoch:  26\n",
            "epoch: 26 |loss: 1.3106598661791893 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.0365)\n",
            "Started epoch:  27\n",
            "epoch: 27 |loss: 1.2913043075992214 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.2929)\n",
            "Started epoch:  28\n",
            "epoch: 28 |loss: 1.2781221789698447 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.2780)\n",
            "Started epoch:  29\n",
            "epoch: 29 |loss: 1.2694734911764822 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.1697)\n",
            "Started epoch:  30\n",
            "epoch: 30 |loss: 1.258241045859552 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.1697)\n",
            "Started epoch:  31\n",
            "epoch: 31 |loss: 1.24966965183135 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.2518)\n",
            "Started epoch:  32\n",
            "epoch: 32 |loss: 1.2919287989216466 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(56.0459)\n",
            "Started epoch:  33\n",
            "epoch: 33 |loss: 1.2612562487202306 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.2630)\n",
            "Started epoch:  34\n",
            "epoch: 34 |loss: 1.234886650116213 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.6140)\n",
            "Started epoch:  35\n",
            "epoch: 35 |loss: 1.2343925583747126 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.6439)\n",
            "Started epoch:  36\n",
            "epoch: 36 |loss: 1.2200917351630427 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(58.0110)\n",
            "Started epoch:  37\n",
            "epoch: 37 |loss: 1.2166458675938268 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.9114)\n",
            "Started epoch:  38\n",
            "epoch: 38 |loss: 1.2110076219804826 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(57.9301)\n",
            "Started epoch:  39\n",
            "epoch: 39 |loss: 1.207171178633167 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(58.1155)\n",
            "Started epoch:  40\n",
            "epoch: 40 |loss: 1.2027556703936668 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(58.2139)\n",
            "Started epoch:  41\n",
            "epoch: 41 |loss: 1.2074066131345687 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(58.2487)\n",
            "Started epoch:  42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7ddbe3c4e8cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBRkuyytG0ab"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6T_gX2y-1d6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZoXwM8jVcSK"
      },
      "source": [
        "# Copying from repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "F19y0XWhUfrC",
        "outputId": "33770e88-94f3-4fd0-a051-0fa67cb7dace"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MLP_for_RRN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_for_RRN, self).__init__()\n",
        "        self.fc1=nn.Linear(input_dim, output_dim)\n",
        "        self.fc2=nn.Linear(output_dim, output_dim)\n",
        "        self.fc3=nn.Linear(output_dim, output_dim)\n",
        "        # self.fc4=nn.Linear(output_dim, output_dim)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.fc1(inp))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        # out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "def compute_cp(pred, true): # pred and true are of shape = batch,81\n",
        "    # number of exactly correct predictions\n",
        "    return torch.sum(torch.sum(pred==true,dim=1)==81)\n",
        "\n",
        "def compute_micro_score(pred, true):\n",
        "    # this finds percentage of correct predicited digits and then averaged over batch\n",
        "    temp = 100.*torch.sum(pred==true,dim=1)/81.\n",
        "    return torch.sum(temp)/temp.shape[0]\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "embed_dim=16\n",
        "sudoku_cells=9\n",
        "hidden_dim=96\n",
        "num_steps=32\n",
        "batch_size=32\n",
        "\n",
        "\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:1500]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:1500]\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[:1024]),torch.tensor(data_Y[:1024]))\n",
        "trainloader=DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "dataset=TensorDataset(torch.tensor(data_X[1024:]),torch.tensor(data_Y[1024:]))\n",
        "testloader=DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "embeds_to_x = MLP_for_RRN(embed_dim, hidden_dim).to(device)\n",
        "message_mlp = MLP_for_RRN(2*hidden_dim, hidden_dim).to(device)\n",
        "mlp_for_lstm_inp = MLP_for_RRN(2*hidden_dim, hidden_dim).to(device)\n",
        "r_to_o_mlp = nn.Linear(hidden_dim, sudoku_cells+1).to(device) # only one linear layer as given in architecture details\n",
        "mlps = [embeds_to_x, message_mlp, mlp_for_lstm_inp, r_to_o_mlp]\n",
        "LSTM = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim).to(device)# since x and m will be concatentated and fed into lstm; x and m are of shape : batch_size*9*9, hidden_dim\n",
        "\n",
        "\n",
        "embed = torch.nn.functional.one_hot ## ALERT\n",
        "\n",
        "# embed_1 = nn.Linear(sudoku_cells+1,embed_dim)\n",
        "\n",
        "# embed_1 = nn.Embedding.from_pretrained(torch.rand(sudoku_cells+1, embed_dim).to(device)).to(device)\n",
        "\n",
        "\n",
        "optimizers = []\n",
        "for mlp in mlps:\n",
        "    optimizers.append(optim.Adam(mlp.parameters(), lr=2e-4, weight_decay=1e-4))\n",
        "optimizers.append(optim.Adam(LSTM.parameters(), lr=2e-4, weight_decay=1e-4))\n",
        "\n",
        "# optimizers.append(optim.Adam(embed_1.parameters(), lr=2e-4, weight_decay=1e-4))\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "############################ get edges\n",
        "# find the required edges in the graph to have communication of message signals\n",
        "indices_of_cells=np.arange(0,sudoku_cells*sudoku_cells).reshape((sudoku_cells,sudoku_cells))\n",
        "edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "for i in range(9):\n",
        "    vector = indices_of_cells[i,:]\n",
        "    edges_row += [(i,j) for i in vector for j in vector if i!=j]\n",
        "    vector = indices_of_cells[:,i]\n",
        "    edges_col += [(i,j) for i in vector for j in vector if i!=j]\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        vector = indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1)\n",
        "        edges_in_3x3 += [(i,j) for i in vector for j in vector if i!=j]\n",
        "\n",
        "edges = list(set(edges_row + edges_col + edges_in_3x3))\n",
        "# edges = [ (i + (b*81), j + (b*81)) for b in range(batch_size) for i,j in edges]\n",
        "edges = torch.tensor(edges).long().to(device)\n",
        "# self.edges contains all the possible pairs of communication between the cells of sudoku\n",
        "############################\n",
        "\n",
        "\n",
        "\n",
        "############################ FOR EMBEDDING ROW, COL INFORMATION\n",
        "# create row and col labels for the cells of sudoku table\n",
        "row_col = []\n",
        "for i in range(sudoku_cells):\n",
        "    for j in range(sudoku_cells):\n",
        "        row_col.append((i,j))\n",
        "row_col = torch.tensor(row_col).long()\n",
        "############################\n",
        "\n",
        "\n",
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "    lss = 0\n",
        "        \n",
        "    total, correct, micro_score = 0, 0, 0\n",
        "\n",
        "    for batch_id, (X,Y) in enumerate(trainloader):\n",
        "        if X.shape[0]!=batch_size:\n",
        "            continue\n",
        "\n",
        "        X = X.flatten()\n",
        "        Y = Y.flatten()\n",
        "        # if epoch == 0 and batch_id == 0:\n",
        "        #     print('printing X shape: ', X.shape)\n",
        "        \n",
        "        X = embed(X.long(), embed_dim).float()\n",
        "        row_col_batched = row_col.repeat(batch_size,1) # IMPORTANT - HERE REMOVE BATCH_SIZE VARIABLE LATER\n",
        "        embedded_row = embed(row_col_batched[:,0].long(), embed_dim).float()\n",
        "        embedded_col = embed(row_col_batched[:,1].long(), embed_dim).float()\n",
        "        \n",
        "        # X = torch.cat([X,embedded_row,embedded_col],dim=1)\n",
        "        # X = F.one_hot(X.long(), sudoku_cells+1).float()\n",
        "        \n",
        "        # if epoch == 0 and batch_id == 0:\n",
        "        #     print('printing embedded X shape: ', X.shape)\n",
        "\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        # X = embed_1(X)\n",
        "\n",
        "        X = embeds_to_x(X)\n",
        "\n",
        "        H = X.detach().clone().to(device)\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "        HiddenState, CellState = torch.zeros(X.shape).to(device), torch.zeros(X.shape).to(device)\n",
        "\n",
        "        for i in range(num_steps):\n",
        "\n",
        "            n_nodes = H.shape[0]\n",
        "            n_edges = edges.shape[0]\n",
        "            n_embed = H.shape[1]\n",
        "            assert n_embed == 96\n",
        "\n",
        "            H = H.view(-1,81,96)\n",
        "\n",
        "            assert H.shape[0] == 32\n",
        "\n",
        "            message_inputs = H[:,edges]\n",
        "            message_inputs = message_inputs.view(-1, 2*96)\n",
        "\n",
        "            messages = message_mlp(message_inputs).view(H.shape[0],-1,96)\n",
        "\n",
        "            updates = torch.zeros(H.shape).to(device)\n",
        "            idx_j = edges[:, 1].to(device)\n",
        "            H = updates.index_add(1, idx_j, messages)\n",
        "\n",
        "            H = H.view(-1,96)\n",
        "\n",
        "            H = mlp_for_lstm_inp(torch.cat([H, X], dim=1))\n",
        "            HiddenState, CellState = LSTM(H, (HiddenState, CellState))\n",
        "\n",
        "            H = HiddenState ## ALERT\n",
        "\n",
        "            Y_pred = r_to_o_mlp(H)\n",
        "\n",
        "            loss += loss_fn(Y_pred, Y.long())\n",
        "\n",
        "        loss /= batch_size\n",
        "\n",
        "        loss.backward()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        lss += loss.item()\n",
        "\n",
        "        Y_pred = Y_pred.argmax(dim=1).view(-1,81)\n",
        "        Y = Y.view(-1,81)\n",
        "\n",
        "        correct_predictions = compute_cp(Y_pred.cpu(),Y.cpu()) # number of exactly correct predictions\n",
        "        correct += correct_predictions\n",
        "        total += Y.shape[0]\n",
        "\n",
        "        micro_correct_digits = compute_micro_score(Y_pred.cpu(),Y.cpu()) # this finds percentage of correct predicited digits and then averaged over batch\n",
        "        micro_score += micro_correct_digits\n",
        "        \n",
        "    micro_score /= batch_id\n",
        "    lss /= batch_id\n",
        "\n",
        "    print(\"epoch:\",epoch,\"|loss:\",lss,\"| Completely correct predictions:\",100.*correct/total,\"| Percentage of Correctly predicted digits:\",micro_score)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 |loss: 2.3409168566426923 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.4695)\n",
            "epoch: 1 |loss: 2.2731815691917174 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.7608)\n",
            "epoch: 2 |loss: 2.2692345803783787 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.9275)\n",
            "epoch: 3 |loss: 2.2683810649379605 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.7894)\n",
            "epoch: 4 |loss: 2.2684452456812703 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(12.0706)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7b9e581d338a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhOFV9bJUiGn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfbLHjc2UiDX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zUOIM4EUiBE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQNpiZjmYe7x"
      },
      "source": [
        "# my implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alMmIKGyJQkn"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MLP_for_RRN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_for_RRN, self).__init__()\n",
        "        self.fc1=nn.Linear(input_dim, output_dim)\n",
        "        self.fc2=nn.Linear(output_dim, output_dim)\n",
        "        self.fc3=nn.Linear(output_dim, output_dim)\n",
        "        # self.fc4=nn.Linear(output_dim, output_dim)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.fc1(inp))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        # out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class RRN(nn.Module):\n",
        "    def __init__(self, embed_dim=16, sudoku_cells=9, hidden_dim=96, num_steps=32, device='cpu'):\n",
        "        # sudoku_cells means we will have sudoku_cells x sudoku_cells in the sudoku table\n",
        "        super(RRN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_steps = num_steps\n",
        "        self.device = device\n",
        "        \n",
        "\n",
        "        ############################ FOR MESSAGE SIGNALS\n",
        "        # find the required edges in the graph to have communication of message signals\n",
        "        indices_of_cells=np.arange(0,sudoku_cells*sudoku_cells).reshape((sudoku_cells,sudoku_cells))\n",
        "        edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "        for i in range(9):\n",
        "            vector = indices_of_cells[i,:]\n",
        "            edges_row += [(i,j) for i in vector for j in vector if i!=j]\n",
        "            vector = indices_of_cells[:,i]\n",
        "            edges_col += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                vector = indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1)\n",
        "                edges_in_3x3 += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        self.edges = torch.tensor(list(set(edges_row + edges_col + edges_in_3x3))).long().to(device)\n",
        "        # self.edges contains all the possible pairs of communication between the cells of sudoku\n",
        "        ############################\n",
        "        \n",
        "        \n",
        "\n",
        "        ############################ FOR EMBEDDING ROW, COL INFORMATION\n",
        "        # create row and col labels for the cells of sudoku table\n",
        "        row_col = []\n",
        "        for i in range(sudoku_cells):\n",
        "            for j in range(sudoku_cells):\n",
        "                row_col.append((i,j))\n",
        "        self.row_col = torch.tensor(row_col).long().to(device)\n",
        "        ############################\n",
        "        \n",
        "        \n",
        "\n",
        "        ############################ EMBEDDING LAYERS\n",
        "        # embedding the cell content {0,1,2,...,sudoku_cells}, row and column information for each cell in sudoku\n",
        "        self.embed_dim = embed_dim\n",
        "        # embed_1_init = torch.rand(sudoku_cells+1, self.embed_dim).to(device) #sudoku_cells+1 because possible digits in input : 0,1,2,3,...,sudoku_cells\n",
        "        # self.embed_1 = nn.Linear(sudoku_cells+1, self.embed_dim)#nn.Embedding.from_pretrained(embed_1_init, freeze=False) \n",
        "        # embed_2_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        # self.embed_2 = nn.Linear(sudoku_cells, self.embed_dim)#nn.Embedding.from_pretrained(embed_2_init, freeze=False)\n",
        "        # embed_3_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        # self.embed_3 = nn.Linear(sudoku_cells, self.embed_dim)#nn.Embedding.from_pretrained(embed_3_init, freeze=False)\n",
        "        ############################\n",
        "\n",
        "\n",
        "        ############################ MLPs\n",
        "        self.embeds_to_x = MLP_for_RRN(embed_dim, hidden_dim)\n",
        "        self.message_mlp = MLP_for_RRN(2*hidden_dim, hidden_dim)\n",
        "        self.mlp_for_lstm_inp = MLP_for_RRN(2*hidden_dim, hidden_dim)\n",
        "        self.r_to_o_mlp = nn.Linear(hidden_dim, sudoku_cells+1) # only one linear layer as given in architecture details\n",
        "        ############################\n",
        "\n",
        "\n",
        "        # LSTM for looping over time i.e. num_steps\n",
        "        self.LSTM = nn.LSTMCell(input_size=hidden_dim, hidden_size=hidden_dim) # since x and m will be concatentated and fed into lstm; x and m are of shape : batch_size*9*9, hidden_dim\n",
        "        \n",
        "        \n",
        "    def forward(self, inp): # inp.shape=batch_size,9*9\n",
        "        bs = inp.shape[0]\n",
        "        inp = inp.view(-1)\n",
        "\n",
        "\n",
        "        # embed the cell content\n",
        "        inp = F.one_hot(inp, self.embed_dim).float()\n",
        "        embedded_inp = inp # batch_size*9*9, embed_dim\n",
        "        \n",
        "        # now also get row and column info of each cell embedded\n",
        "        row_col = self.row_col.repeat(batch_size, 1)\n",
        "        inp_row = F.one_hot(row_col[:,0], self.embed_dim).float()\n",
        "        embedded_row = inp_row\n",
        "        inp_col = F.one_hot(row_col[:,1], self.embed_dim).float()\n",
        "        embedded_col = inp_col\n",
        "        \n",
        "        embedded_all = torch.cat([embedded_inp,embedded_row,embedded_col], dim=1)\n",
        "        # x = self.embeds_to_x(embedded_all) # batch_size*9*9, hidden_dim\n",
        "        x = embedded_inp\n",
        "        \n",
        "        assert x.shape[1] == self.hidden_dim\n",
        "        \n",
        "\n",
        "        # x will be concatenated with m and then fed into LSTM\n",
        "        # find message signals : over time i.e. num_steps\n",
        "        # m_{i,j}^{t} = MLP(h_{i}^{t-1}, h_{j}^{t-1} \n",
        "        # since m^t requires h^{t-1}, maintain a list of h and c\n",
        "        # cell state is also required since we will use LSTM cell and loop over LSTM cell num_steps times\n",
        "        \n",
        "        h_for_msgs = x.detach().clone().to(self.device)\n",
        "        o_t = []\n",
        "\n",
        "        for t in range(self.num_steps):\n",
        "\n",
        "            h_for_msgs = h_for_msgs.view(-1, 81, self.hidden_dim)\n",
        "            inp_for_msgs = h_for_msgs[:,self.edges].view(-1, 2*self.hidden_dim)\n",
        "            msgs = self.message_mlp(inp_for_msgs).view(bs, -1, self.hidden_dim)\n",
        "            \n",
        "\n",
        "            # now sum up the message signals appropriately\n",
        "            final_msgs = torch.zeros(h_for_msgs.shape).to(device)\n",
        "            indices = self.edges[:,1].to(device)\n",
        "            final_msgs = final_msgs.index_add(1, indices, msgs) # shape : batch_size, 81, self.hidden_dim\n",
        "            final_msgs = final_msgs.view(-1, self.hidden_dim)\n",
        "            \n",
        "            # h_for_msgs = h_for_msgs.view(-1, self.hidden_dim) # required for input to lstm cell\n",
        "            \n",
        "            inp_to_lstm = self.mlp_for_lstm_inp(torch.cat([final_msgs,x],dim=1))\n",
        "            h, c = self.LSTM(inp_to_lstm, (h,c)) if t!=0 else self.LSTM(inp_to_lstm, (h_for_msgs.view(-1, 96), torch.zeros(x.shape).to(device)))\n",
        "            \n",
        "            h_for_msgs = h\n",
        "\n",
        "            o = self.r_to_o_mlp(h)\n",
        "            o_t.append(o)\n",
        "        \n",
        "        out = torch.stack(o_t) # shape : num_steps, batch_size*9*9, sudoku_cells+1\n",
        "        return out # out.shape = num_steps, batch_size*9*9, 10 : last dim is without-softmax over sudoku_cells(10)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKwjxQuiovrg",
        "outputId": "a9d15c01-b21b-4e29-c2b8-5e072f4ba7c1"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_cp(pred, true): # pred and true are of shape = batch,81\n",
        "    # number of exactly correct predictions\n",
        "    return torch.sum(torch.sum(pred==true,dim=1)==81)\n",
        "\n",
        "def compute_micro_score(pred, true):\n",
        "    # this finds percentage of correct predicited digits and then averaged over batch\n",
        "    temp = 100.*torch.sum(pred==true,dim=1)/81.\n",
        "    return torch.sum(temp)/temp.shape[0]\n",
        "\n",
        "batch_size=32\n",
        "embed_dim=16\n",
        "sudoku_cells=9\n",
        "hidden_dim=96\n",
        "num_steps=32\n",
        "device='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:1500]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:1500]\n",
        "dataset=TensorDataset(torch.tensor(data_X),torch.tensor(data_Y))\n",
        "data_loader=DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "model = RRN(embed_dim=embed_dim, sudoku_cells=sudoku_cells, hidden_dim=hidden_dim, num_steps=num_steps, device=device)\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "loss_fn=nn.CrossEntropyLoss()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RRN(\n",
            "  (embeds_to_x): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=48, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (message_mlp): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (mlp_for_lstm_inp): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (r_to_o_mlp): Linear(in_features=96, out_features=10, bias=True)\n",
            "  (LSTM): LSTMCell(96, 96)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "jc0_fgSAqL9q",
        "outputId": "8cb69ccb-4816-49ce-ee99-b2be2d9cb5f8"
      },
      "source": [
        "num_epochs=100\n",
        "train_loss=[]\n",
        "for epoch in range(num_epochs):\n",
        "    lss=0\n",
        "\n",
        "    total, correct, micro_score = 0, 0, 0\n",
        "\n",
        "    for batch_id, (X,Y) in enumerate(data_loader):\n",
        "        if X.shape[0] != batch_size:\n",
        "            continue\n",
        "\n",
        "        X, Y = X.to(device).long(), Y.to(device)\n",
        "        Y = Y.view(-1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        Y_ = model(X)\n",
        "        \n",
        "        l=0\n",
        "        for i in range(num_steps):\n",
        "            ls=loss_fn(Y_[i],Y.long())\n",
        "            l+=ls\n",
        "\n",
        "        Y_pred = Y_[-1].argmax(dim=1)\n",
        "\n",
        "        l /= batch_size\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        Y_pred = Y_pred.view(-1,81)\n",
        "        Y = Y.view(-1,81)\n",
        "        \n",
        "        assert X.shape[0]==Y.shape[0]\n",
        "\n",
        "        lss += l.item()\n",
        "        correct_predictions = compute_cp(Y_pred.cpu(),Y.cpu()) # number of exactly correct predictions\n",
        "        correct += correct_predictions\n",
        "        total += Y.shape[0]\n",
        "\n",
        "        micro_correct_digits = compute_micro_score(Y_pred.cpu(),Y.cpu()) # this finds percentage of correct predicited digits and then averaged over batch\n",
        "        micro_score += micro_correct_digits\n",
        "        \n",
        "    lss /= batch_id\n",
        "    micro_score /= batch_id\n",
        "    print(\"epoch:\",epoch,\"|\tloss:\",lss,\"| Completely correct predictions:\",100.*correct/total,\"| Percentage of Correctly predicted digits:\",micro_score)\n",
        "    \n",
        "    # scheduler.step(lss)\n",
        "\n",
        "torch.save(model.state_dict(),'RRN.pth')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 |\tloss: 2.2518762246422144 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 1 |\tloss: 2.199477926544521 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 2 |\tloss: 2.1981215476989746 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.3216)\n",
            "epoch: 3 |\tloss: 2.1978320505308067 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1832)\n",
            "epoch: 4 |\tloss: 2.1976953744888306 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1170)\n",
            "epoch: 5 |\tloss: 2.1975963271182515 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 6 |\tloss: 2.1975375880365786 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 7 |\tloss: 2.197492376617763 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 8 |\tloss: 2.197453840919163 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 9 |\tloss: 2.1974227843077285 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 10 |\tloss: 2.197399512581203 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 11 |\tloss: 2.197382496750873 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 12 |\tloss: 2.19736923860467 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 13 |\tloss: 2.197358172872792 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 14 |\tloss: 2.197348786436993 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 15 |\tloss: 2.197340322577435 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 16 |\tloss: 2.197333009346672 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 17 |\tloss: 2.197326017462689 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 18 |\tloss: 2.1973199170568716 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 19 |\tloss: 2.1973145941029424 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 20 |\tloss: 2.197309110475623 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 21 |\tloss: 2.197303834168807 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n",
            "epoch: 22 |\tloss: 2.1972993508629175 | Completely correct predictions: tensor(0.) | Percentage of Correctly predicted digits: tensor(11.1111)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6d50122db331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2386\u001b[0m         )\n\u001b[1;32m   2387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE-1T04KUfQc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuwuVmaGUfNJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jchJJCD2UfKJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEgcNzvKL9mg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IA2qkrkHF6z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgykbYcPCFbK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRpB0MpNUgA2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIPk-qwgUf-F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwW6ih0VUf8a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLDGKGeIUf5r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypz2hcl8Uf2Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}