{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "A2_RRN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkjsQG1JQkF"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UbIwRwjiIk7",
        "outputId": "9b36c8ad-f58a-4735-b524-ff707c688982"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:512]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:512]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew505WhpJQkY"
      },
      "source": [
        "class MLP_for_RRN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_for_RRN, self).__init__()\n",
        "        self.fc1=nn.Linear(input_dim, output_dim)\n",
        "        self.fc2=nn.Linear(output_dim, output_dim)\n",
        "        self.fc3=nn.Linear(output_dim, output_dim)\n",
        "        self.fc4=nn.Linear(output_dim, output_dim)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.fc1(inp))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.relu(self.fc3(out))\n",
        "        out = self.fc4(out)\n",
        "        return out"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pELbKzwJQka"
      },
      "source": [
        "class RRN(nn.Module):\n",
        "    def __init__(self, embed_dim=16, sudoku_cells=9, hidden_dim=96, num_steps=32, device='cpu'):\n",
        "        # sudoku_cells means we will have sudoku_cells x sudoku_cells in the sudoku table\n",
        "        super(RRN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_steps = num_steps\n",
        "        self.device = device\n",
        "        \n",
        "        # find the required edges in the graph to have communication of message signals\n",
        "        indices_of_cells=np.arange(0,sudoku_cells*sudoku_cells).reshape((sudoku_cells,sudoku_cells))\n",
        "        edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "        for i in range(9):\n",
        "            vector = indices_of_cells[i,:]\n",
        "            edges_row += [(i,j) for i in vector for j in vector if i!=j]\n",
        "            vector = indices_of_cells[:,i]\n",
        "            edges_col += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                vector = indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1)\n",
        "                edges_in_3x3 += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        self.edges = torch.tensor(list(set(edges_row + edges_col + edges_in_3x3))).long().to(device)\n",
        "        # self.edges contains all the possible pairs of communication between the cells of sudoku\n",
        "        \n",
        "        # create row and col labels for the cells of sudoku table\n",
        "        rows, cols = [],[]\n",
        "        for i in range(sudoku_cells):\n",
        "            rows += [i]*sudoku_cells\n",
        "            cols += [i]\n",
        "        cols = cols*sudoku_cells\n",
        "        self.rows, self.cols = torch.tensor(rows).long().to(device), torch.tensor(cols).long().to(device)\n",
        "        \n",
        "        # embedding the cell content {0,1,2,...,sudoku_cells}, row and column information for each cell in sudoku\n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        # embed_1_init = torch.rand(sudoku_cells+1, self.embed_dim).to(device) #sudoku_cells+1 because possible digits in input : 0,1,2,3,...,sudoku_cells\n",
        "        self.embed_1 = nn.Linear(sudoku_cells+1, self.embed_dim)#nn.Embedding.from_pretrained(embed_1_init, freeze=False) \n",
        "        \n",
        "        # embed_2_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        self.embed_2 = nn.Linear(sudoku_cells, self.embed_dim)#nn.Embedding.from_pretrained(embed_2_init, freeze=False)\n",
        "        \n",
        "        # embed_3_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        self.embed_3 = nn.Linear(sudoku_cells, self.embed_dim)#nn.Embedding.from_pretrained(embed_3_init, freeze=False)\n",
        "        \n",
        "        # MLPs\n",
        "        self.embeds_to_x = MLP_for_RRN(3*embed_dim, hidden_dim)\n",
        "        self.message_mlp = MLP_for_RRN(2*hidden_dim, hidden_dim)\n",
        "        self.r_to_o_mlp = nn.Linear(hidden_dim, sudoku_cells) # only one linear layer as given in architecture details\n",
        "\n",
        "        # LSTM for looping over time i.e. num_steps\n",
        "        self.LSTM = nn.LSTMCell(input_size=2*hidden_dim, hidden_size=hidden_dim) # since x and m will be concatentated and fed into lstm; x and m are of shape : batch_size*9*9, hidden_dim\n",
        "        \n",
        "        \n",
        "    def forward(self, inp): # inp.shape=batch_size,9*9\n",
        "        batch_size = inp.shape[0]\n",
        "        inp = inp.view(-1)\n",
        "        inp = F.one_hot(inp).float()\n",
        "        embedded_inp = self.embed_1(inp) # batch_size*9*9, embed_dim\n",
        "        \n",
        "        # now also get row and column info of each cell embedded\n",
        "        inp_row = self.rows.repeat(batch_size)\n",
        "        inp_row = F.one_hot(inp_row).float()\n",
        "        embedded_row = self.embed_2(inp_row)\n",
        "        inp_col = self.cols.repeat(batch_size)\n",
        "        inp_col = F.one_hot(inp_col).float()\n",
        "        embedded_col = self.embed_3(inp_col)\n",
        "        \n",
        "        embedded_all = torch.cat((embedded_inp,embedded_row,embedded_col),dim=-1)\n",
        "        x = self.embeds_to_x(embedded_all) # batch_size*9*9, hidden_dim\n",
        "        \n",
        "        assert x.shape[1] == self.hidden_dim\n",
        "\n",
        "        # x will be concatenated with m and then fed into LSTM\n",
        "        # find message signals : over time i.e. num_steps\n",
        "        # m_{i,j}^{t} = MLP(h_{i}^{t-1}, h_{j}^{t-1} \n",
        "        # since m^t requires h^{t-1}, maintain a list of h and c\n",
        "        # cell state is also required since we will use LSTM cell and loop over LSTM cell num_steps times\n",
        "        \n",
        "        h_0=x.clone().to(self.device)#.clone().\n",
        "        h_t, c_t, o_t = [h_0],[torch.zeros(x.shape).to(device)],[]\n",
        "        for t in range(self.num_steps):\n",
        "            h = h_t[-1].view(batch_size,-1,self.hidden_dim)\n",
        "            inp_for_msgs = h[:,self.edges].view(-1,2*self.hidden_dim)\n",
        "            msgs = self.message_mlp(inp_for_msgs).view(batch_size,-1,self.hidden_dim)\n",
        "            \n",
        "            # now sum up the message signals appropriately\n",
        "            final_msgs = torch.zeros(h.shape).to(device)\n",
        "            final_msgs = final_msgs.index_add(1, self.edges[:,1], msgs) # shape : batch_size, 81, self.hidden_dim\n",
        "            \n",
        "            h = h.view(-1, self.hidden_dim)\n",
        "            c = c_t[-1]\n",
        "            final_msgs = final_msgs.view(-1, self.hidden_dim)\n",
        "            \n",
        "            inp_to_lstm = torch.cat((x,final_msgs),dim=-1)\n",
        "            h_new, c_new = self.LSTM(inp_to_lstm, (h,c))\n",
        "            \n",
        "            h_t.append(h_new)\n",
        "            c_t.append(c_new)\n",
        "            \n",
        "            o_new = self.r_to_o_mlp(h_new)\n",
        "            o_t.append(o_new)\n",
        "        \n",
        "        out = torch.stack(o_t) # shape : num_steps, batch_size*9*9, sudoku_cells\n",
        "        return out # out.shape = num_steps, batch_size*9*9, 9 : last dim is without-softmax over sudoku_cells(9)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBUvk6EKJQkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e80a82-7506-40ac-f15b-6c31658e6dd7"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "model = RRN(embed_dim=16, sudoku_cells=9, hidden_dim=96, num_steps=32, device=device)\n",
        "print(model)\n",
        "\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
        "\n",
        "# print(data_X[:2])\n",
        "batch_size=32\n",
        "dataset=TensorDataset(torch.tensor(data_X),torch.tensor(data_Y))\n",
        "data_loader=DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "model = model.to(device)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RRN(\n",
            "  (embed_1): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (embed_2): Linear(in_features=9, out_features=16, bias=True)\n",
            "  (embed_3): Linear(in_features=9, out_features=16, bias=True)\n",
            "  (embeds_to_x): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=48, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc4): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (message_mlp): MLP_for_RRN(\n",
            "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
            "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
            "    (fc4): Linear(in_features=96, out_features=96, bias=True)\n",
            "  )\n",
            "  (r_to_o_mlp): Linear(in_features=96, out_features=9, bias=True)\n",
            "  (LSTM): LSTMCell(192, 96)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "1wNws_9AJQkk",
        "outputId": "5e5db09d-d36a-49d6-ec68-8f880dfbe61c"
      },
      "source": [
        "num_epochs=100\n",
        "train_loss,acc=[],[]\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    lss=0\n",
        "    total,correct=0,0\n",
        "    for batch_id, (X,Y) in enumerate(data_loader):\n",
        "        X, Y = X.to(device).long(), Y.to(device).long()\n",
        "        X = X.view(batch_size,-1)\n",
        "        Y = Y.view(-1)\n",
        "        Y = Y-1\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        Y_ = model(X)\n",
        "        \n",
        "        l=0\n",
        "        for i in range(32):\n",
        "            l+=loss_fn(Y_[i],Y)\n",
        "\n",
        "        Y_pred = Y_[-1].argmax(dim=1)\n",
        "\n",
        "        l /= batch_size\n",
        "\n",
        "        l.backward()\n",
        "        print(l.grad)\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
        "        optimizer.step()\n",
        "\n",
        "        lss += l.item()\n",
        "        correct += torch.all(Y_pred.view(batch_size,-1)==Y.view(batch_size,-1),dim=1).cpu().sum()\n",
        "        total+=batch_size\n",
        "    acc.append(correct/total)\n",
        "    lss /= batch_id\n",
        "    if epoch%10==0:\n",
        "        print(\"epoch\",epoch,\"loss\",lss,\"acc\",acc[-1])\n",
        "    train_loss.append(lss)\n",
        "    scheduler.step(lss)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "epoch 0 loss 1.6374902804692586 acc tensor(0.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _releaseLock at 0x7f661eb1b8c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
            "    def _releaseLock():\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-c7323bff7ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "BVO7tj3gKzDS",
        "outputId": "745ed592-361c-43ff-a2cf-fd4c49a61144"
      },
      "source": [
        "plt.plot(train_loss)\n",
        "plt.show()\n",
        "plt.plot(acc)\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT6oJFdFJQkk"
      },
      "source": [
        "Y=Y.view(batch_size, -1)\n",
        "Y_pred=Y_pred.view(batch_size, -1)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxXXcKmnJQkk",
        "outputId": "9ec281c8-de9a-402f-d5f1-0d08a8dda7b3"
      },
      "source": [
        "print(Y.shape)\n",
        "print(Y.view(batch_size,9,9)[-1])\n",
        "print(Y_pred.shape)\n",
        "print(Y_pred.view(batch_size,9,9)[-1])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 81])\n",
            "tensor([[6, 3, 0, 5, 1, 8, 2, 7, 4],\n",
            "        [1, 2, 4, 6, 0, 7, 8, 5, 3],\n",
            "        [7, 8, 5, 2, 3, 4, 0, 6, 1],\n",
            "        [2, 6, 8, 7, 4, 0, 1, 3, 5],\n",
            "        [0, 5, 3, 1, 6, 2, 7, 4, 8],\n",
            "        [4, 1, 7, 8, 5, 3, 6, 2, 0],\n",
            "        [5, 0, 6, 4, 7, 1, 3, 8, 2],\n",
            "        [3, 7, 2, 0, 8, 5, 4, 1, 6],\n",
            "        [8, 4, 1, 3, 2, 6, 5, 0, 7]], device='cuda:0')\n",
            "torch.Size([32, 81])\n",
            "tensor([[3, 6, 1, 7, 1, 7, 5, 7, 5],\n",
            "        [5, 5, 5, 5, 1, 5, 5, 5, 3],\n",
            "        [5, 1, 5, 2, 5, 4, 6, 6, 6],\n",
            "        [5, 6, 1, 7, 5, 5, 1, 3, 5],\n",
            "        [1, 5, 5, 5, 3, 6, 6, 5, 5],\n",
            "        [4, 1, 7, 1, 5, 3, 6, 2, 5],\n",
            "        [6, 6, 5, 5, 5, 1, 5, 1, 5],\n",
            "        [6, 7, 2, 1, 7, 5, 4, 6, 3],\n",
            "        [6, 4, 6, 3, 7, 3, 5, 6, 7]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaIIKKGWJQkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d04faf-a098-47b7-ad6f-4ccee0354620"
      },
      "source": [
        "Y=Y.view(batch_size,-1)\n",
        "Y_pred=Y_pred.view(batch_size,-1)\n",
        "torch.all(Y==Y_pred, dim=1).cpu().sum()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH_RpRl_JQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csSYr96vJQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao1AxrH6JQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D17An0v-JQkm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alMmIKGyJQkn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24mmC48eJQkn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCCagvHHJQko"
      },
      "source": [
        "Took idea from [here](https://github.com/wDaniec/pytorch-RNN/blob/master/main.py) to implement message signals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKamw6ExJQko"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmhayKvfJQkp"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_size, HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc_out = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "    \n",
        "class Pred(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Pred, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VADVgsAJQkp"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMB_SIZE = 16\n",
        "HIDDEN_SIZE = 96\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhWFY9g3JQkp"
      },
      "source": [
        "def get_start_embeds(embed, X):\n",
        "    X = embed(X, EMB_SIZE).float()\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBZwUBjkJQkp"
      },
      "source": [
        "mlp1 = MLP(EMB_SIZE).to(device)\n",
        "mlp2 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "mlp3 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "r = Pred(HIDDEN_SIZE).to(device)\n",
        "lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE).to(device)\n",
        "embed = torch.nn.functional.one_hot\n",
        "\n",
        "optimizer_mlp1 = torch.optim.Adam(mlp1.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp2 = torch.optim.Adam(mlp2.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp3 = torch.optim.Adam(mlp3.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_r = torch.optim.Adam(r.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "optimizers = [optimizer_mlp1, optimizer_mlp2, optimizer_mlp3, optimizer_r, optimizer_lstm]\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OLLtgCKJQkq"
      },
      "source": [
        "def cross(a):\n",
        "    return [(i, j) for i in a.flatten() for j in a.flatten() if not i == j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kXyxQhLJQkq",
        "outputId": "9d18e0cb-1b9f-4511-844e-ebf0bc192f32"
      },
      "source": [
        "idx = np.arange(81).reshape(9, 9)\n",
        "idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
              "       [ 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
              "       [18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
              "       [27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
              "       [36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
              "       [45, 46, 47, 48, 49, 50, 51, 52, 53],\n",
              "       [54, 55, 56, 57, 58, 59, 60, 61, 62],\n",
              "       [63, 64, 65, 66, 67, 68, 69, 70, 71],\n",
              "       [72, 73, 74, 75, 76, 77, 78, 79, 80]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cqYpH71JQkr"
      },
      "source": [
        "rows, columns, squares = [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2rOnLlLZJQkr"
      },
      "source": [
        "for i in range(9):\n",
        "    rows += cross(idx[i, :])\n",
        "    columns += cross(idx[:, i])\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        squares += cross(idx[i * 3:(i + 1) * 3, j * 3:(j + 1) * 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBWB9jF0JQkr",
        "outputId": "2391f5f3-38bc-4c45-b3be-da1da381ac6d"
      },
      "source": [
        "edges = list(set(rows + columns + squares))\n",
        "print(edges[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(40, 22), (7, 25), (1, 64), (79, 76), (44, 34)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpZkz5wPJQkr"
      },
      "source": [
        "# batched_edges = [(i + (b * 81), j + (b * 81)) for b in range(BATCH_SIZE) for i, j in edges]\n",
        "# batched_edges = torch.Tensor(batched_edges).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTYz-i14JQks",
        "outputId": "5f2415ba-7388-4a81-a193-207f2a693024"
      },
      "source": [
        "# print(batched_edges.shape)\n",
        "# print(batched_edges.view(32,-1,2).shape)\n",
        "# print(batched_edges.view(32,-1,2)[0,:5,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([51840, 2])\n",
            "torch.Size([32, 1620, 2])\n",
            "tensor([[40, 22],\n",
            "        [ 7, 25],\n",
            "        [ 1, 64],\n",
            "        [79, 76],\n",
            "        [44, 34]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE23bJfgJQks"
      },
      "source": [
        "# edges = batched_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuRLgguTJQks",
        "outputId": "740c9507-2916-4391-cee7-5afb9fc61fc5"
      },
      "source": [
        "edges = torch.tensor(edges).long()\n",
        "print(edges.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1620, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c66x5VpYJQkt",
        "outputId": "7bfec21b-58c8-4193-816c-1b6f85d4bfc6"
      },
      "source": [
        "X,Y=next(iter(data_loader))\n",
        "print(X.shape,Y.shape)\n",
        "X = X.flatten()\n",
        "Y = Y.flatten()\n",
        "X = get_start_embeds(embed, X.long())\n",
        "X = X.to(device)\n",
        "Y = Y.to(device)\n",
        "X = mlp1(X)\n",
        "print(X.shape, X.view(32,-1,96).shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 9, 9]) torch.Size([32, 9, 9])\n",
            "torch.Size([2592, 96]) torch.Size([32, 81, 96]) torch.Size([2592])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5tzYKKqJQkt"
      },
      "source": [
        "for optimizer in optimizers:\n",
        "    optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkB74sLmJQkt"
      },
      "source": [
        "H = X#.detach().clone().to(device)\n",
        "loss = 0\n",
        "CellState = torch.zeros(X.shape).to(device)\n",
        "HiddenState = H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbyxTBgJQku",
        "outputId": "f43a2f5e-d22e-4195-9b50-712d5ff1b608"
      },
      "source": [
        "H=H.view(batch_size,-1,96)\n",
        "H.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 81, 96])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKzvl8_GJQku",
        "outputId": "a02d0425-e0df-4942-e2f9-c22821931126"
      },
      "source": [
        "message_inputs = H[:,edges]\n",
        "print(H.shape, edges.shape, message_inputs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 81, 96]) torch.Size([1620, 2]) torch.Size([32, 1620, 2, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkwW-HSJQku",
        "outputId": "8da5da83-a5f1-4171-f769-f688e7494457"
      },
      "source": [
        "message_inputs = message_inputs.view(-1, 2*96)\n",
        "messages = mlp2(message_inputs)\n",
        "print(messages.shape)\n",
        "messages=messages.view(batch_size,edges.shape[0],96)\n",
        "print(messages.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([51840, 96])\n",
            "torch.Size([32, 1620, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1gVAX6UJQkz",
        "outputId": "1250ffcf-230b-400d-830d-eb25287aa9a0"
      },
      "source": [
        "edges[:, 0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1620])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4996E9zrJQk0",
        "outputId": "790c7d8c-68c3-4a84-a06f-9be2f2b37904"
      },
      "source": [
        "updates = torch.zeros(H.shape).to(device)\n",
        "idx_j = edges[:, 1].long().to(device)\n",
        "updates = updates.index_add(1, idx_j, messages)\n",
        "print(updates.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 81, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ-8lxB4JQk0",
        "outputId": "51e2f929-240e-47f7-a605-7f23c9abba54"
      },
      "source": [
        "# let us dry run : whether or not index_add works as we expect\n",
        "# basically : index_add does the following -- it sums up the elements getting index value x, \n",
        "# and puts it at index x in updates\n",
        "random_inp = torch.rand(2,6)\n",
        "random_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2233, 0.6432, 0.3769, 0.9756, 0.9678, 0.9828],\n",
              "        [0.0304, 0.5316, 0.3088, 0.7876, 0.1165, 0.8560]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRas0PZhJQk0",
        "outputId": "3c067a7b-c163-48d1-f146-cd8770d4a91a"
      },
      "source": [
        "oup = torch.zeros(2,4)\n",
        "ind = torch.randint(4,(6,))\n",
        "ind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 2, 2, 3, 0, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-DbtVSJQk1",
        "outputId": "7b4ecf81-8b55-4350-f722-eda8dd740704"
      },
      "source": [
        "oup = oup.index_add(1,ind,random_inp)\n",
        "oup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9678, 0.0000, 1.0201, 2.1818],\n",
              "        [0.1165, 0.0000, 0.8405, 1.6740]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MftMGyo9JQk1",
        "outputId": "7bdb7569-525b-4d46-8619-d1cbabe62df8"
      },
      "source": [
        "print(0.2233+0.9756+0.9828)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwfxScAyJQk2",
        "outputId": "85dd3674-604e-4ddf-f3eb-2d4b7365afce"
      },
      "source": [
        "print(0.0304+0.7876+0.8560)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlDmo39WJQk2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# sys.stdout = open('lologi.txt', 'w')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMB_SIZE = 16\n",
        "HIDDEN_SIZE = 96\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv = np.array(pd.read_csv(csv_file, sep=',', header=None))\n",
        "        self.csv = torch.Tensor([[[int(x) for x in my_input] for my_input in problem] for problem in self.csv]).long()\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # res = torch.Tensor([[int(x) for x in sudoku] for sudoku in self.csv[idx]]).long()\n",
        "        # return res\n",
        "        return self.csv[idx][0], self.csv[idx][1]\n",
        "\n",
        "def get_edges():\n",
        "    def cross(a):\n",
        "        return [(i, j) for i in a.flatten() for j in a.flatten() if not i == j]\n",
        "\n",
        "    idx = np.arange(81).reshape(9, 9)\n",
        "    rows, columns, squares = [], [], []\n",
        "    for i in range(9):\n",
        "        rows += cross(idx[i, :])\n",
        "        columns += cross(idx[:, i])\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            squares += cross(idx[i * 3:(i + 1) * 3, j * 3:(j + 1) * 3])\n",
        "    \n",
        "    edges_base = list(set(rows + columns + squares))\n",
        "    batched_edges = [(i + (b * 81), j + (b * 81)) for b in range(BATCH_SIZE) for i, j in edges_base]\n",
        "    return torch.Tensor(batched_edges).long()\n",
        "\n",
        "def get_start_embeds(embed, X):\n",
        "    # rows = embed(torch.Tensor([i // 9 for i in range(81)]).long(), EMB_SIZE).repeat(X.shape[0] // 81, 1) # beznadziejne rozwiazanie !!!!\n",
        "    # columns = embed(torch.Tensor([i % 9 for i in range(81)]).long(), EMB_SIZE).repeat(X.shape[0] // 81, 1) # beznadziejne rozwiazanie, tez !!\n",
        "    # X = torch.cat([embed(X, EMB_SIZE), rows, columns], dim=1).float()\n",
        "    X = embed(X, EMB_SIZE).float()\n",
        "     \n",
        "    return X\n",
        "\n",
        "\n",
        "def message_passing(nodes, edges, message_fn):\n",
        "    n_nodes = nodes.shape[0]\n",
        "    n_edges = edges.shape[0]\n",
        "    n_embed = nodes.shape[1]\n",
        "\n",
        "    message_inputs = nodes[edges]\n",
        "    message_inputs = message_inputs.view(n_edges, 2*n_embed)\n",
        "    messages = message_fn(message_inputs)\n",
        "\n",
        "    updates = torch.zeros(n_nodes, n_embed).to(device)\n",
        "    idx_j = edges[:, 1].to(device)\n",
        "    updates = updates.index_add(0, idx_j, messages)\n",
        "    return updates\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_size, HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc_out = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "class Pred(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Pred, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "def one_hot(num):\n",
        "    return torch.Tensor\n",
        "\n",
        "traindataset = MyDataset('train.csv')\n",
        "trainloader = DataLoader(traindataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n",
        "testdataset = MyDataset('test.csv')\n",
        "testloader = DataLoader(testdataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n",
        "mlp1 = MLP(EMB_SIZE).to(device)\n",
        "mlp2 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "mlp3 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "r = Pred(HIDDEN_SIZE).to(device)\n",
        "lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE).to(device)\n",
        "embed = torch.nn.functional.one_hot\n",
        "\n",
        "optimizer_mlp1 = torch.optim.Adam(mlp1.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp2 = torch.optim.Adam(mlp2.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp3 = torch.optim.Adam(mlp3.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_r = torch.optim.Adam(r.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "optimizers = [optimizer_mlp1, optimizer_mlp2, optimizer_mlp3, optimizer_r, optimizer_lstm]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "edges = get_edges()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "def check_val():\n",
        "    with torch.no_grad():\n",
        "        almost_correct = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        my_dict = [0 for i in range(82)]\n",
        "        for batch_id, (X_batched, Y_batched) in enumerate(testloader):\n",
        "            if X_batched.shape[0] != BATCH_SIZE:\n",
        "                continue\n",
        "            X = X_batched.flatten()\n",
        "\n",
        "            X = get_start_embeds(embed, X)\n",
        "            X = X.to(device)\n",
        "            Y_batched = Y_batched.to(device)\n",
        "            X = mlp1(X)\n",
        "            H = X.detach().clone().to(device)\n",
        "\n",
        "            CellState = torch.zeros(X.shape).to(device)\n",
        "            HiddenState = torch.zeros(X.shape).to(device)\n",
        "            for i in range(32):\n",
        "                H = message_passing(H, edges, mlp2) # message_fn\n",
        "                H = mlp3(torch.cat([H, X], dim=1))\n",
        "                HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "                H = CellState\n",
        "                pred = r(H)\n",
        "\n",
        "\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "            pred = pred.view(-1, 81)\n",
        "            amam = torch.sum(pred == Y_batched, dim=1)\n",
        "            for x in amam:\n",
        "                my_dict[x.item()] += 1\n",
        "\n",
        "            # if batch_id % 100 == 0:\n",
        "            #     print(\"validation: \", batch_id, '/', len(testloader))\n",
        "\n",
        "            # print(torch.sum(X != 0, dim=1))\n",
        "            correct += torch.sum(torch.sum(pred == Y_batched, dim=1) == 81)\n",
        "            almost_correct += torch.sum(torch.sum(pred == Y_batched, dim=1) >= 60)\n",
        "            total += Y_batched.shape[0]\n",
        "        \n",
        "        for i, x in enumerate(my_dict):\n",
        "            print(i, \": \", x)\n",
        "        \n",
        "        print(\"Correctly solved: {}, out of: {}\".format(correct, total))\n",
        "        print(\"Almost correctly solved: {}, out of: {}\".format(almost_correct, total))\n",
        "\n",
        "\n",
        "for epoch in range(1000):\n",
        "    running_loss = 0\n",
        "    print(\"Started epoch: \", epoch)\n",
        "    for batch_id, (X, Y) in enumerate(trainloader):\n",
        "        if X.shape[0] != BATCH_SIZE:\n",
        "            continue\n",
        "        X = X.flatten()\n",
        "        Y = Y.flatten()\n",
        "\n",
        "        X = get_start_embeds(embed, X)\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        X = mlp1(X)\n",
        "        H = X.detach().clone().to(device)\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        loss = 0\n",
        "        CellState = torch.zeros(X.shape).to(device)\n",
        "        HiddenState = torch.zeros(X.shape).to(device)\n",
        "        for i in range(32):\n",
        "            H = message_passing(H, edges, mlp2) # message_fn\n",
        "            H = mlp3(torch.cat([H, X], dim=1))\n",
        "            HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "            H = CellState\n",
        "            pred = r(H)\n",
        "            \n",
        "            loss += criterion(pred, Y)\n",
        "        \n",
        "        loss /= BATCH_SIZE\n",
        "        running_loss += loss\n",
        "        const = 200\n",
        "        if(batch_id % const == 0):\n",
        "            print(\"trainset: {} / {}\".format(batch_id, len(trainloader)), end= \" | \")\n",
        "            print(\"{:.6f} updates/s\".format( const / (time.time() - start_time)), end=\" | \")\n",
        "            print(\"train_loss: {:.6f}\".format(running_loss.item() / const))\n",
        "            running_loss = 0\n",
        "            sys.stdout.flush()\n",
        "            start_time = time.time()\n",
        "        loss.backward()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "    check_val()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLBv8JuiJQk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4beu-8BJQk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}