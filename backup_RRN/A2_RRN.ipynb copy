{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "A2_RRN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQkjsQG1JQkF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-OW2dwbJQkU"
      },
      "source": [
        "# num_cells=81 \n",
        "# batch_size=32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHVAEJd-JQkV"
      },
      "source": [
        "# # let us assume symbolic dataset for simplicity\n",
        "# X=torch.randint(low=0,high=10,size=(100,num_cells)) # we will create such symbolic data from the image of sudoku\n",
        "# Y=torch.randint(low=1,high=10,size=(100,num_cells)) # this will be the output of RRN\n",
        "# print(\"X:\",X.shape,\"Y:\",Y.shape)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEP5CwPvJQkW"
      },
      "source": [
        "# import numpy as np\n",
        "# quizzes = np.zeros((1000000, 81), np.int32)\n",
        "# solutions = np.zeros((1000000, 81), np.int32)\n",
        "# for i, line in enumerate(open('sudoku.csv', 'r').read().splitlines()[1:]):\n",
        "#     quiz, solution = line.split(\",\")\n",
        "#     for j, q_s in enumerate(zip(quiz, solution)):\n",
        "#         q, s = q_s\n",
        "#         quizzes[i, j] = q\n",
        "#         solutions[i, j] = s\n",
        "# data_X = quizzes.reshape((-1, 9, 9))\n",
        "# data_Y = solutions.reshape((-1, 9, 9))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPN7oxybJQkX"
      },
      "source": [
        "# print(data_X.shape,data_Y.shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLk8gs0xJQkX"
      },
      "source": [
        "# np.save('sample_X.npy',data_X)\n",
        "# np.save('sample_Y.npy',data_Y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew505WhpJQkY"
      },
      "source": [
        "class MLP_for_RRN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP_for_RRN, self).__init__()\n",
        "        self.fc1=nn.Linear(input_dim, output_dim)\n",
        "        self.fc2=nn.Linear(output_dim, output_dim)\n",
        "        self.fc3=nn.Linear(output_dim, output_dim)\n",
        "        self.fc4=nn.Linear(output_dim, output_dim)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        out = F.relu(self.fc1(inp))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.relu(self.fc3(out))\n",
        "        out = self.fc4(out)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9zLjx1pJQkY"
      },
      "source": [
        "# indices_of_cells=np.arange(0,81).reshape((9,9))\n",
        "# def find_pairs(vector):\n",
        "#     return [(i,j) for i in vector for j in vector if i!=j]\n",
        "# edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "# for i in range(9):\n",
        "#     edges_row += find_pairs(indices_of_cells[i,:])\n",
        "#     edges_col += find_pairs(indices_of_cells[:,i])\n",
        "# for i in range(3):\n",
        "#     for j in range(3):\n",
        "#         edges_in_3x3 += find_pairs(indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1))\n",
        "# edges = torch.tensor(list(set(edges_row + edges_col + edges_in_3x3)))\n",
        "# print(edges[:5])\n",
        "# print(edges.shape)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMTfAh24JQkZ"
      },
      "source": [
        "# batch_size=32\n",
        "# edges_for_batch = edges.repeat(batch_size,1).long()\n",
        "# print(edges_for_batch.shape)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tv8KXxnJQkZ"
      },
      "source": [
        "# batch_size=32\n",
        "# edges_for_batch = edges.repeat(32)\n",
        "# edges_for_batch = torch.tensor(edges_for_batch).long()\n",
        "# print(edges_for_batch.shape)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPCydEI1JQkZ"
      },
      "source": [
        "# x=edges_for_batch.view(batch_size,-1,2)\n",
        "# x.shape"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHQWCObaJQka"
      },
      "source": [
        "# x[1,:5]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnYcLSzIJQka"
      },
      "source": [
        "# sudoku_cells=9\n",
        "# rows, cols = [],[]\n",
        "# for i in range(sudoku_cells):\n",
        "#     rows += [i]*sudoku_cells\n",
        "#     cols += [i]\n",
        "# cols = cols*sudoku_cells\n",
        "# print(rows)\n",
        "# print(cols)\n",
        "# rows, cols = torch.tensor(rows).long(), torch.tensor(cols).long()\n",
        "# print(rows.shape, cols.shape)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pELbKzwJQka"
      },
      "source": [
        "class RRN(nn.Module):\n",
        "    def __init__(self, embed_dim=16, sudoku_cells=9, hidden_dim=96, num_steps=32, device='cpu'):\n",
        "        # sudoku_cells means we will have sudoku_cells x sudoku_cells in the sudoku table\n",
        "        super(RRN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_steps = num_steps\n",
        "        self.device = device\n",
        "        \n",
        "        # find the required edges in the graph to have communication of message signals\n",
        "        indices_of_cells=np.arange(0,sudoku_cells*sudoku_cells).reshape((sudoku_cells,sudoku_cells))\n",
        "        edges_row, edges_col, edges_in_3x3=[],[],[]\n",
        "        for i in range(9):\n",
        "            vector = indices_of_cells[i,:]\n",
        "            edges_row += [(i,j) for i in vector for j in vector if i!=j]\n",
        "            vector = indices_of_cells[:,i]\n",
        "            edges_col += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                vector = indices_of_cells[3*i:3*(i+1),3*j:3*(j+1)].reshape(-1)\n",
        "                edges_in_3x3 += [(i,j) for i in vector for j in vector if i!=j]\n",
        "        self.edges = torch.tensor(list(set(edges_row + edges_col + edges_in_3x3))).long().to(device)\n",
        "        # self.edges contains all the possible pairs of communication between the cells of sudoku\n",
        "        \n",
        "        # create row and col labels for the cells of sudoku table\n",
        "        rows, cols = [],[]\n",
        "        for i in range(sudoku_cells):\n",
        "            rows += [i]*sudoku_cells\n",
        "            cols += [i]\n",
        "        cols = cols*sudoku_cells\n",
        "        self.rows, self.cols = torch.tensor(rows).long().to(device), torch.tensor(cols).long().to(device)\n",
        "        \n",
        "        # embedding the cell content {0,1,2,...,sudoku_cells}, row and column information for each cell in sudoku\n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        embed_1_init = torch.rand(sudoku_cells+1, self.embed_dim).to(device) #sudoku_cells+1 because possible digits in input : 0,1,2,3,...,sudoku_cells\n",
        "        self.embed_1 = nn.Embedding.from_pretrained(embed_1_init, freeze=False) # CHECK with harman if this will learn or not\n",
        "        \n",
        "        embed_2_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        self.embed_2 = nn.Embedding.from_pretrained(embed_2_init, freeze=False)\n",
        "        \n",
        "        embed_3_init = torch.rand(sudoku_cells, self.embed_dim).to(device)\n",
        "        self.embed_3 = nn.Embedding.from_pretrained(embed_3_init, freeze=False)\n",
        "        \n",
        "        # MLPs\n",
        "        self.embeds_to_x = MLP_for_RRN(3*embed_dim, hidden_dim)\n",
        "        self.message_mlp = MLP_for_RRN(2*hidden_dim, hidden_dim)\n",
        "        self.r_to_o_mlp = nn.Linear(hidden_dim, sudoku_cells) # only one linear layer as given in architecture details\n",
        "        \n",
        "        # LSTM for looping over time i.e. num_steps\n",
        "        self.LSTM = nn.LSTMCell(input_size=2*hidden_dim, hidden_size=hidden_dim) # since x and h will be concatentated and fed into lstm; x and h are of shape : batch_size, hidden_dim\n",
        "        \n",
        "        \n",
        "    def forward(self, inp): # inp.shape=batch_size,9*9\n",
        "        batch_size = inp.shape[0]\n",
        "        inp = inp.view(-1)\n",
        "        embedded_inp = self.embed_1(inp) # batch_size*9*9, embed_dim\n",
        "        \n",
        "        # now also get row and column info of each cell embedded\n",
        "        inp_row = self.rows.repeat(batch_size)\n",
        "        embedded_row = self.embed_2(inp_row)\n",
        "        inp_col = self.cols.repeat(batch_size)\n",
        "        embedded_col = self.embed_3(inp_col)\n",
        "        \n",
        "        embedded_all = torch.cat((embedded_inp,embedded_row,embedded_col),dim=-1)\n",
        "        x = self.embeds_to_x(embedded_all) # batch_size*9*9, hidden_dim\n",
        "        \n",
        "        assert x.shape[1] == self.hidden_dim\n",
        "\n",
        "        # x will be concatenated with m and then fed into LSTM\n",
        "        # find message signals : over time i.e. num_steps\n",
        "        # m_{i,j}^{t} = MLP(h_{i}^{t-1}, h_{j}^{t-1} \n",
        "        # since m^t requires h^{t-1}, maintain a list of h and c\n",
        "        # cell state is also required since we will use LSTM cell and loop over LSTM cell num_steps times\n",
        "        \n",
        "        h_t, c_t, o_t = [x],[torch.zeros(x.shape).to(device)], []\n",
        "        for t in range(self.num_steps):\n",
        "            h = h_t[-1].view(batch_size,-1,self.hidden_dim)\n",
        "            inp_for_msgs = h[:,self.edges].view(-1,2*self.hidden_dim)\n",
        "            msgs = self.message_mlp(inp_for_msgs).view(batch_size,-1,self.hidden_dim)\n",
        "            \n",
        "            # now sum up the message signals appropriately\n",
        "            final_msgs = torch.zeros(h.shape).to(device)\n",
        "            final_msgs = final_msgs.index_add(1, self.edges[:,1], msgs) # shape : batch_size, 81, self.hidden_dim\n",
        "            \n",
        "            h = h.view(-1, self.hidden_dim)\n",
        "            c = c_t[-1]\n",
        "            final_msgs = final_msgs.view(-1, self.hidden_dim)\n",
        "            \n",
        "            inp_to_lstm = torch.cat((x,final_msgs),dim=-1)\n",
        "            h_new, c_new = self.LSTM(inp_to_lstm, (h,c))\n",
        "            \n",
        "            h_t.append(h_new)\n",
        "            c_t.append(c_new)\n",
        "            \n",
        "            o_new = self.r_to_o_mlp(h_new)\n",
        "            o_t.append(o_new)\n",
        "        \n",
        "        out = torch.stack(o_t) # shape : num_steps, batch_size*9*9, sudoku_cells\n",
        "        return out # out.shape = num_steps, batch_size*9*9, 9 : last dim is without-softmax over sudoku_cells(9)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L29pgWh5JQkg",
        "outputId": "477c8a8d-1d43-4210-92f2-34f83461880b"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "model = RRN()\n",
        "model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RRN(\n",
              "  (embed_1): Embedding(10, 16)\n",
              "  (embed_2): Embedding(9, 16)\n",
              "  (embed_3): Embedding(9, 16)\n",
              "  (embeds_to_x): MLP_for_RRN(\n",
              "    (fc1): Linear(in_features=48, out_features=96, bias=True)\n",
              "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
              "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
              "    (fc4): Linear(in_features=96, out_features=96, bias=True)\n",
              "  )\n",
              "  (message_mlp): MLP_for_RRN(\n",
              "    (fc1): Linear(in_features=192, out_features=96, bias=True)\n",
              "    (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
              "    (fc3): Linear(in_features=96, out_features=96, bias=True)\n",
              "    (fc4): Linear(in_features=96, out_features=96, bias=True)\n",
              "  )\n",
              "  (r_to_o_mlp): Linear(in_features=96, out_features=9, bias=True)\n",
              "  (LSTM): LSTMCell(192, 96)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rV8OnNpJQkj"
      },
      "source": [
        "optimizer=torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "loss_fn=nn.CrossEntropyLoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3FLB8BqQY5H"
      },
      "source": [
        "data_X=np.load('drive/My Drive/Colab Notebooks/COL870/sample_X.npy')[:128]\n",
        "data_Y=np.load('drive/My Drive/Colab Notebooks/COL870/sample_Y.npy')[:128]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBUvk6EKJQkj"
      },
      "source": [
        "# print(data_X[:2])\n",
        "batch_size=16\n",
        "dataset=TensorDataset(torch.tensor(data_X),torch.tensor(data_Y))\n",
        "data_loader=DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "model = model.to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "1wNws_9AJQkk",
        "outputId": "69f05d1f-4267-480c-9cf0-36a4dfdda48e"
      },
      "source": [
        "num_epochs=10\n",
        "train_loss=[]\n",
        "for epoch in range(num_epochs):\n",
        "    lss=0\n",
        "    acc=0\n",
        "    for batch_id, (X,Y) in enumerate(data_loader):\n",
        "        X, Y = X.to(device).long(), Y.to(device).long()\n",
        "        X = X.view(batch_size,-1)\n",
        "        Y = Y.view(-1)\n",
        "        Y = Y-1\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        Y_ = model(X)\n",
        "        \n",
        "        l=0\n",
        "        for i in range(32):\n",
        "            l+=loss_fn(Y_[i],Y)\n",
        "\n",
        "        Y_pred = Y_[-1].argmax(dim=1)\n",
        "\n",
        "        l /= batch_size\n",
        "\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        lss += l.item()\n",
        "    \n",
        "    acc /= (batch_id*batch_size)\n",
        "    lss /= batch_id\n",
        "    print(lss,acc)\n",
        "    train_loss.append(lss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0e5fdceee10d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "BVO7tj3gKzDS",
        "outputId": "e5913e81-d102-49b8-cb6a-31b6dc98fffe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2c9ac9a310>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT6oJFdFJQkk"
      },
      "source": [
        "Y=Y.view(batch_size, -1)\n",
        "Y_pred=Y_pred.view(batch_size, -1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxXXcKmnJQkk",
        "outputId": "4b9dc80c-f8bf-4ad3-9842-59bda54ff67f"
      },
      "source": [
        "print(Y[0])\n",
        "print(Y_pred[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 3, 2, 8, 1, 6, 5, 7, 4, 1, 4, 5, 0, 7, 3, 8, 6, 2, 7, 8, 6, 4, 2, 5,\n",
            "        0, 3, 1, 3, 1, 7, 2, 4, 8, 6, 0, 5, 6, 2, 0, 3, 5, 1, 7, 4, 8, 8, 5, 4,\n",
            "        7, 6, 0, 1, 2, 3, 2, 6, 8, 1, 0, 4, 3, 5, 7, 5, 7, 1, 6, 3, 2, 4, 8, 0,\n",
            "        4, 0, 3, 5, 8, 7, 2, 1, 6])\n",
            "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaIIKKGWJQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH_RpRl_JQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csSYr96vJQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao1AxrH6JQkl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D17An0v-JQkm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alMmIKGyJQkn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24mmC48eJQkn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCCagvHHJQko"
      },
      "source": [
        "Took idea from [here](https://github.com/wDaniec/pytorch-RNN/blob/master/main.py) to implement message signals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKamw6ExJQko"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmhayKvfJQkp"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_size, HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc_out = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "    \n",
        "class Pred(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Pred, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VADVgsAJQkp"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMB_SIZE = 16\n",
        "HIDDEN_SIZE = 96\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhWFY9g3JQkp"
      },
      "source": [
        "def get_start_embeds(embed, X):\n",
        "    X = embed(X, EMB_SIZE).float()\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBZwUBjkJQkp"
      },
      "source": [
        "mlp1 = MLP(EMB_SIZE).to(device)\n",
        "mlp2 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "mlp3 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "r = Pred(HIDDEN_SIZE).to(device)\n",
        "lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE).to(device)\n",
        "embed = torch.nn.functional.one_hot\n",
        "\n",
        "optimizer_mlp1 = torch.optim.Adam(mlp1.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp2 = torch.optim.Adam(mlp2.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp3 = torch.optim.Adam(mlp3.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_r = torch.optim.Adam(r.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "optimizers = [optimizer_mlp1, optimizer_mlp2, optimizer_mlp3, optimizer_r, optimizer_lstm]\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OLLtgCKJQkq"
      },
      "source": [
        "def cross(a):\n",
        "    return [(i, j) for i in a.flatten() for j in a.flatten() if not i == j]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kXyxQhLJQkq",
        "outputId": "9d18e0cb-1b9f-4511-844e-ebf0bc192f32"
      },
      "source": [
        "idx = np.arange(81).reshape(9, 9)\n",
        "idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
              "       [ 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
              "       [18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
              "       [27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
              "       [36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
              "       [45, 46, 47, 48, 49, 50, 51, 52, 53],\n",
              "       [54, 55, 56, 57, 58, 59, 60, 61, 62],\n",
              "       [63, 64, 65, 66, 67, 68, 69, 70, 71],\n",
              "       [72, 73, 74, 75, 76, 77, 78, 79, 80]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cqYpH71JQkr"
      },
      "source": [
        "rows, columns, squares = [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2rOnLlLZJQkr"
      },
      "source": [
        "for i in range(9):\n",
        "    rows += cross(idx[i, :])\n",
        "    columns += cross(idx[:, i])\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        squares += cross(idx[i * 3:(i + 1) * 3, j * 3:(j + 1) * 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBWB9jF0JQkr",
        "outputId": "2391f5f3-38bc-4c45-b3be-da1da381ac6d"
      },
      "source": [
        "edges = list(set(rows + columns + squares))\n",
        "print(edges[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(40, 22), (7, 25), (1, 64), (79, 76), (44, 34)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpZkz5wPJQkr"
      },
      "source": [
        "# batched_edges = [(i + (b * 81), j + (b * 81)) for b in range(BATCH_SIZE) for i, j in edges]\n",
        "# batched_edges = torch.Tensor(batched_edges).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTYz-i14JQks",
        "outputId": "5f2415ba-7388-4a81-a193-207f2a693024"
      },
      "source": [
        "# print(batched_edges.shape)\n",
        "# print(batched_edges.view(32,-1,2).shape)\n",
        "# print(batched_edges.view(32,-1,2)[0,:5,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([51840, 2])\n",
            "torch.Size([32, 1620, 2])\n",
            "tensor([[40, 22],\n",
            "        [ 7, 25],\n",
            "        [ 1, 64],\n",
            "        [79, 76],\n",
            "        [44, 34]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE23bJfgJQks"
      },
      "source": [
        "# edges = batched_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuRLgguTJQks",
        "outputId": "740c9507-2916-4391-cee7-5afb9fc61fc5"
      },
      "source": [
        "edges = torch.tensor(edges).long()\n",
        "print(edges.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1620, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c66x5VpYJQkt",
        "outputId": "7bfec21b-58c8-4193-816c-1b6f85d4bfc6"
      },
      "source": [
        "X,Y=next(iter(data_loader))\n",
        "print(X.shape,Y.shape)\n",
        "X = X.flatten()\n",
        "Y = Y.flatten()\n",
        "X = get_start_embeds(embed, X.long())\n",
        "X = X.to(device)\n",
        "Y = Y.to(device)\n",
        "X = mlp1(X)\n",
        "print(X.shape, X.view(32,-1,96).shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 9, 9]) torch.Size([32, 9, 9])\n",
            "torch.Size([2592, 96]) torch.Size([32, 81, 96]) torch.Size([2592])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5tzYKKqJQkt"
      },
      "source": [
        "for optimizer in optimizers:\n",
        "    optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkB74sLmJQkt"
      },
      "source": [
        "H = X#.detach().clone().to(device)\n",
        "loss = 0\n",
        "CellState = torch.zeros(X.shape).to(device)\n",
        "HiddenState = H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbyxTBgJQku",
        "outputId": "f43a2f5e-d22e-4195-9b50-712d5ff1b608"
      },
      "source": [
        "H=H.view(batch_size,-1,96)\n",
        "H.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 81, 96])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKzvl8_GJQku",
        "outputId": "a02d0425-e0df-4942-e2f9-c22821931126"
      },
      "source": [
        "message_inputs = H[:,edges]\n",
        "print(H.shape, edges.shape, message_inputs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 81, 96]) torch.Size([1620, 2]) torch.Size([32, 1620, 2, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkwW-HSJQku",
        "outputId": "8da5da83-a5f1-4171-f769-f688e7494457"
      },
      "source": [
        "message_inputs = message_inputs.view(-1, 2*96)\n",
        "messages = mlp2(message_inputs)\n",
        "print(messages.shape)\n",
        "messages=messages.view(batch_size,edges.shape[0],96)\n",
        "print(messages.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([51840, 96])\n",
            "torch.Size([32, 1620, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1gVAX6UJQkz",
        "outputId": "1250ffcf-230b-400d-830d-eb25287aa9a0"
      },
      "source": [
        "edges[:, 0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1620])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4996E9zrJQk0",
        "outputId": "790c7d8c-68c3-4a84-a06f-9be2f2b37904"
      },
      "source": [
        "updates = torch.zeros(H.shape).to(device)\n",
        "idx_j = edges[:, 1].long().to(device)\n",
        "updates = updates.index_add(1, idx_j, messages)\n",
        "print(updates.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 81, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ-8lxB4JQk0",
        "outputId": "51e2f929-240e-47f7-a605-7f23c9abba54"
      },
      "source": [
        "# let us dry run : whether or not index_add works as we expect\n",
        "# basically : index_add does the following -- it sums up the elements getting index value x, \n",
        "# and puts it at index x in updates\n",
        "random_inp = torch.rand(2,6)\n",
        "random_inp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2233, 0.6432, 0.3769, 0.9756, 0.9678, 0.9828],\n",
              "        [0.0304, 0.5316, 0.3088, 0.7876, 0.1165, 0.8560]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRas0PZhJQk0",
        "outputId": "3c067a7b-c163-48d1-f146-cd8770d4a91a"
      },
      "source": [
        "oup = torch.zeros(2,4)\n",
        "ind = torch.randint(4,(6,))\n",
        "ind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 2, 2, 3, 0, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-DbtVSJQk1",
        "outputId": "7b4ecf81-8b55-4350-f722-eda8dd740704"
      },
      "source": [
        "oup = oup.index_add(1,ind,random_inp)\n",
        "oup"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9678, 0.0000, 1.0201, 2.1818],\n",
              "        [0.1165, 0.0000, 0.8405, 1.6740]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MftMGyo9JQk1",
        "outputId": "7bdb7569-525b-4d46-8619-d1cbabe62df8"
      },
      "source": [
        "print(0.2233+0.9756+0.9828)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwfxScAyJQk2",
        "outputId": "85dd3674-604e-4ddf-f3eb-2d4b7365afce"
      },
      "source": [
        "print(0.0304+0.7876+0.8560)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlDmo39WJQk2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# sys.stdout = open('lologi.txt', 'w')\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMB_SIZE = 16\n",
        "HIDDEN_SIZE = 96\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv = np.array(pd.read_csv(csv_file, sep=',', header=None))\n",
        "        self.csv = torch.Tensor([[[int(x) for x in my_input] for my_input in problem] for problem in self.csv]).long()\n",
        "    def __len__(self):\n",
        "        return self.csv.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # res = torch.Tensor([[int(x) for x in sudoku] for sudoku in self.csv[idx]]).long()\n",
        "        # return res\n",
        "        return self.csv[idx][0], self.csv[idx][1]\n",
        "\n",
        "def get_edges():\n",
        "    def cross(a):\n",
        "        return [(i, j) for i in a.flatten() for j in a.flatten() if not i == j]\n",
        "\n",
        "    idx = np.arange(81).reshape(9, 9)\n",
        "    rows, columns, squares = [], [], []\n",
        "    for i in range(9):\n",
        "        rows += cross(idx[i, :])\n",
        "        columns += cross(idx[:, i])\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            squares += cross(idx[i * 3:(i + 1) * 3, j * 3:(j + 1) * 3])\n",
        "    \n",
        "    edges_base = list(set(rows + columns + squares))\n",
        "    batched_edges = [(i + (b * 81), j + (b * 81)) for b in range(BATCH_SIZE) for i, j in edges_base]\n",
        "    return torch.Tensor(batched_edges).long()\n",
        "\n",
        "def get_start_embeds(embed, X):\n",
        "    # rows = embed(torch.Tensor([i // 9 for i in range(81)]).long(), EMB_SIZE).repeat(X.shape[0] // 81, 1) # beznadziejne rozwiazanie !!!!\n",
        "    # columns = embed(torch.Tensor([i % 9 for i in range(81)]).long(), EMB_SIZE).repeat(X.shape[0] // 81, 1) # beznadziejne rozwiazanie, tez !!\n",
        "    # X = torch.cat([embed(X, EMB_SIZE), rows, columns], dim=1).float()\n",
        "    X = embed(X, EMB_SIZE).float()\n",
        "     \n",
        "    return X\n",
        "\n",
        "\n",
        "def message_passing(nodes, edges, message_fn):\n",
        "    n_nodes = nodes.shape[0]\n",
        "    n_edges = edges.shape[0]\n",
        "    n_embed = nodes.shape[1]\n",
        "\n",
        "    message_inputs = nodes[edges]\n",
        "    message_inputs = message_inputs.view(n_edges, 2*n_embed)\n",
        "    messages = message_fn(message_inputs)\n",
        "\n",
        "    updates = torch.zeros(n_nodes, n_embed).to(device)\n",
        "    idx_j = edges[:, 1].to(device)\n",
        "    updates = updates.index_add(0, idx_j, messages)\n",
        "    return updates\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_in = nn.Linear(input_size, HIDDEN_SIZE)\n",
        "        self.fc = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc_out = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc_in(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "class Pred(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Pred, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "def one_hot(num):\n",
        "    return torch.Tensor\n",
        "\n",
        "traindataset = MyDataset('train.csv')\n",
        "trainloader = DataLoader(traindataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n",
        "testdataset = MyDataset('test.csv')\n",
        "testloader = DataLoader(testdataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4)\n",
        "\n",
        "mlp1 = MLP(EMB_SIZE).to(device)\n",
        "mlp2 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "mlp3 = MLP(2*HIDDEN_SIZE).to(device)\n",
        "r = Pred(HIDDEN_SIZE).to(device)\n",
        "lstm = nn.LSTMCell(HIDDEN_SIZE, HIDDEN_SIZE).to(device)\n",
        "embed = torch.nn.functional.one_hot\n",
        "\n",
        "optimizer_mlp1 = torch.optim.Adam(mlp1.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp2 = torch.optim.Adam(mlp2.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_mlp3 = torch.optim.Adam(mlp3.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_r = torch.optim.Adam(r.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "optimizer_lstm = torch.optim.Adam(lstm.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n",
        "optimizers = [optimizer_mlp1, optimizer_mlp2, optimizer_mlp3, optimizer_r, optimizer_lstm]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "edges = get_edges()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "def check_val():\n",
        "    with torch.no_grad():\n",
        "        almost_correct = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        my_dict = [0 for i in range(82)]\n",
        "        for batch_id, (X_batched, Y_batched) in enumerate(testloader):\n",
        "            if X_batched.shape[0] != BATCH_SIZE:\n",
        "                continue\n",
        "            X = X_batched.flatten()\n",
        "\n",
        "            X = get_start_embeds(embed, X)\n",
        "            X = X.to(device)\n",
        "            Y_batched = Y_batched.to(device)\n",
        "            X = mlp1(X)\n",
        "            H = X.detach().clone().to(device)\n",
        "\n",
        "            CellState = torch.zeros(X.shape).to(device)\n",
        "            HiddenState = torch.zeros(X.shape).to(device)\n",
        "            for i in range(32):\n",
        "                H = message_passing(H, edges, mlp2) # message_fn\n",
        "                H = mlp3(torch.cat([H, X], dim=1))\n",
        "                HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "                H = CellState\n",
        "                pred = r(H)\n",
        "\n",
        "\n",
        "            pred = torch.argmax(pred, dim=1)\n",
        "\n",
        "            pred = pred.view(-1, 81)\n",
        "            amam = torch.sum(pred == Y_batched, dim=1)\n",
        "            for x in amam:\n",
        "                my_dict[x.item()] += 1\n",
        "\n",
        "            # if batch_id % 100 == 0:\n",
        "            #     print(\"validation: \", batch_id, '/', len(testloader))\n",
        "\n",
        "            # print(torch.sum(X != 0, dim=1))\n",
        "            correct += torch.sum(torch.sum(pred == Y_batched, dim=1) == 81)\n",
        "            almost_correct += torch.sum(torch.sum(pred == Y_batched, dim=1) >= 60)\n",
        "            total += Y_batched.shape[0]\n",
        "        \n",
        "        for i, x in enumerate(my_dict):\n",
        "            print(i, \": \", x)\n",
        "        \n",
        "        print(\"Correctly solved: {}, out of: {}\".format(correct, total))\n",
        "        print(\"Almost correctly solved: {}, out of: {}\".format(almost_correct, total))\n",
        "\n",
        "\n",
        "for epoch in range(1000):\n",
        "    running_loss = 0\n",
        "    print(\"Started epoch: \", epoch)\n",
        "    for batch_id, (X, Y) in enumerate(trainloader):\n",
        "        if X.shape[0] != BATCH_SIZE:\n",
        "            continue\n",
        "        X = X.flatten()\n",
        "        Y = Y.flatten()\n",
        "\n",
        "        X = get_start_embeds(embed, X)\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        X = mlp1(X)\n",
        "        H = X.detach().clone().to(device)\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        loss = 0\n",
        "        CellState = torch.zeros(X.shape).to(device)\n",
        "        HiddenState = torch.zeros(X.shape).to(device)\n",
        "        for i in range(32):\n",
        "            H = message_passing(H, edges, mlp2) # message_fn\n",
        "            H = mlp3(torch.cat([H, X], dim=1))\n",
        "            HiddenState, CellState = lstm(H, (HiddenState, CellState))\n",
        "            H = CellState\n",
        "            pred = r(H)\n",
        "            \n",
        "            loss += criterion(pred, Y)\n",
        "        \n",
        "        loss /= BATCH_SIZE\n",
        "        running_loss += loss\n",
        "        const = 200\n",
        "        if(batch_id % const == 0):\n",
        "            print(\"trainset: {} / {}\".format(batch_id, len(trainloader)), end= \" | \")\n",
        "            print(\"{:.6f} updates/s\".format( const / (time.time() - start_time)), end=\" | \")\n",
        "            print(\"train_loss: {:.6f}\".format(running_loss.item() / const))\n",
        "            running_loss = 0\n",
        "            sys.stdout.flush()\n",
        "            start_time = time.time()\n",
        "        loss.backward()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "    check_val()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLBv8JuiJQk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4beu-8BJQk3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}